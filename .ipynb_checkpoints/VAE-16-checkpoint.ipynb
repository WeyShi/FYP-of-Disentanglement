{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a JointVAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST data\n",
    "Build a simple JointVAE model on MNIST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from utils.dataloaders import get_mnist_dataloaders, get_celeba_dataloader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "IMAGE_PATH = 'img_align_celeba/'\n",
    "image_size = 64\n",
    "# SAMPLE_PATH = '../'\n",
    "\n",
    "# if not os.path.exists(SAMPLE_PATH):\n",
    "#     os.makedirs(SAMPLE_PATH)\n",
    "    \n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    #transforms.Scale(image_size),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop((image_size,image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "data_loader = ImageFolder(IMAGE_PATH, transform)\n",
    "\n",
    "\n",
    "#data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "valid_loader, train_loader, test_loader = get_celeba_dataloader(data_loader, \n",
    "                                                                batch_size=128)\n",
    "test_batch = iter(test_loader)\n",
    "test_batch = next(test_batch)\n",
    "new_labels =torch.tensor(test_batch[1])\n",
    "print(torch.tensor(test_batch[0]).shape)\n",
    "#latent_dist = model.encode(torch.tensor(test_batch[0]).cuda())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "limit_a, limit_b, epsilon = -.5, 1.5, 1e-6\n",
    "eps = np.linspace(0.1,0.9,20)\n",
    "def sigmoid(x):\n",
    "    y = 1./(1.+np.exp(-x))\n",
    "    return y\n",
    "def quantile_concrete(x,temperature,qz_loga):\n",
    "        \n",
    "        \"\"\"Implements the quantile, aka inverse CDF, of the 'stretched' concrete distribution\"\"\"\n",
    "        y = sigmoid((np.log(x) - np.log(1 - x) + qz_loga) / temperature)\n",
    "        return y * (limit_b - limit_a) + limit_a\n",
    "\n",
    "z = quantile_concrete(eps,1/20,2)\n",
    "z[z>=1]=1\n",
    "z[z<=0]=0\n",
    "print(z)\n",
    "plt.plot(eps,z)\n",
    "droprate_init = 0.2\n",
    "x = torch.autograd.Variable(torch.Tensor([1, 2, 3, 4]), requires_grad=True)\n",
    "y = torch.autograd.Variable(torch.zeros(4), requires_grad=False).data.normal_(math.log(1 - droprate_init) - math.log(droprate_init), 1e-2)\n",
    "z=(x+y).detach()\n",
    "print(y)\n",
    "#z.is_leaf \n",
    "a=torch.ones((64,32))\n",
    "b=torch.ones((1,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define latent distribution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (img_to_features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (features_to_hidden): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc_mean): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (fc_log_var): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (fc_alphas): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=42, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (features_to_img): Sequential(\n",
      "    (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloaders import get_mnist_dataloaders, get_celeba_dataloader \n",
    "from torchvision import transforms \n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader \n",
    "import os \n",
    "import torch\n",
    "from jointvae.VAEmodel import VAE\n",
    "from jointvae.training_l import Trainer\n",
    "from torch import optim\n",
    "from viz.visualize_l import Visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "valid_loader, train_loader, test_loader = get_mnist_dataloaders(batch_size=64)\n",
    "\n",
    "# Latent distribution will be joint distribution of 10 gaussian normal distributions  7-14\n",
    "# and one 10 dimensional Gumbel Softmax distribution\n",
    "n_cont = 32\n",
    "disc = [10]\n",
    "n_disc = len(disc)\n",
    "latent_spec = {'cont': n_cont,\n",
    "               'disc': disc}\n",
    "\n",
    "device = torch.device('cuda')\n",
    "#model = VAE(latent_spec=latent_spec, img_size=(3, 64, 64)).cuda()\n",
    "model = VAE(latent_spec=latent_spec, img_size=(1, 32, 32)).cuda()\n",
    "print(model)\n",
    "\n",
    "\n",
    "lr=5e-4\n",
    "# Build optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# Define the capacities\n",
    "# Continuous channels\n",
    "gamma=1.0\n",
    "cont_capacity = [0.0, 0.0, 25000, gamma]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "# Discrete channels\n",
    "disc_capacity = [0.0, 0.0, 25000, gamma]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "\n",
    "\n",
    "lambda_d = 2\n",
    "lambda_od = 10*lambda_d\n",
    "lambda_dis = 30*lambda_d \n",
    "path=\"ReportFig/DIP-VAE/cont_{}/gamma_ {}lambda{}\".format(n_cont,gamma,lambda_d)\n",
    "# Build a trainer\n",
    "trainer = Trainer(model, optimizer,\n",
    "                  cont_capacity=cont_capacity,\n",
    "                  disc_capacity=disc_capacity,lambda_d = lambda_d,\n",
    "                  lambda_od = lambda_od, lambda_dis = lambda_dis )\n",
    "# Build a visualizer which will be passed to trainer to visualize progress during training\n",
    "viz = Visualizer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from jointvae.training import Trainer\n",
    "\n",
    "\n",
    "trainer._train_epoch(train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/54000\tLoss: 278.913\n",
      "3200/54000\tLoss: 193.912\n",
      "6400/54000\tLoss: 125.248\n",
      "9600/54000\tLoss: 120.027\n",
      "12800/54000\tLoss: 117.367\n",
      "16000/54000\tLoss: 115.871\n",
      "19200/54000\tLoss: 114.018\n",
      "22400/54000\tLoss: 110.096\n",
      "25600/54000\tLoss: 105.965\n",
      "28800/54000\tLoss: 103.578\n",
      "32000/54000\tLoss: 101.614\n",
      "35200/54000\tLoss: 100.405\n",
      "38400/54000\tLoss: 99.525\n",
      "41600/54000\tLoss: 98.332\n",
      "44800/54000\tLoss: 98.135\n",
      "48000/54000\tLoss: 96.619\n",
      "51200/54000\tLoss: 95.746\n",
      "Valid Loss: 94.205, Recon Error: 0.030\n",
      "94.2051767389825\n",
      "Epoch: 1 Average loss: 111.63 Valid loss: 94.2051767389825\tRecon Error:0.030\n",
      "0/54000\tLoss: 92.978\n",
      "3200/54000\tLoss: 94.410\n",
      "6400/54000\tLoss: 93.922\n",
      "9600/54000\tLoss: 93.398\n",
      "12800/54000\tLoss: 92.843\n",
      "16000/54000\tLoss: 92.870\n",
      "19200/54000\tLoss: 92.324\n",
      "22400/54000\tLoss: 91.727\n",
      "25600/54000\tLoss: 91.687\n",
      "28800/54000\tLoss: 91.238\n",
      "32000/54000\tLoss: 90.923\n",
      "35200/54000\tLoss: 90.478\n",
      "38400/54000\tLoss: 90.608\n",
      "41600/54000\tLoss: 90.398\n",
      "44800/54000\tLoss: 89.874\n",
      "48000/54000\tLoss: 89.864\n",
      "51200/54000\tLoss: 89.579\n",
      "Valid Loss: 89.036, Recon Error: 0.023\n",
      "89.03582398434902\n",
      "Epoch: 2 Average loss: 91.57 Valid loss: 89.03582398434902\tRecon Error:0.023\n",
      "0/54000\tLoss: 89.861\n",
      "3200/54000\tLoss: 89.149\n",
      "6400/54000\tLoss: 88.938\n",
      "9600/54000\tLoss: 88.359\n",
      "12800/54000\tLoss: 88.409\n",
      "16000/54000\tLoss: 89.069\n",
      "19200/54000\tLoss: 88.512\n",
      "22400/54000\tLoss: 88.214\n",
      "25600/54000\tLoss: 87.716\n",
      "28800/54000\tLoss: 88.109\n",
      "32000/54000\tLoss: 87.883\n",
      "35200/54000\tLoss: 88.002\n",
      "38400/54000\tLoss: 87.288\n",
      "41600/54000\tLoss: 87.259\n",
      "44800/54000\tLoss: 86.659\n",
      "48000/54000\tLoss: 87.538\n",
      "51200/54000\tLoss: 87.150\n",
      "Valid Loss: 86.787, Recon Error: 0.021\n",
      "86.78709111315139\n",
      "Epoch: 3 Average loss: 88.01 Valid loss: 86.78709111315139\tRecon Error:0.021\n",
      "0/54000\tLoss: 86.006\n",
      "3200/54000\tLoss: 86.510\n",
      "6400/54000\tLoss: 87.080\n",
      "9600/54000\tLoss: 86.088\n",
      "12800/54000\tLoss: 86.189\n",
      "16000/54000\tLoss: 86.359\n",
      "19200/54000\tLoss: 86.063\n",
      "22400/54000\tLoss: 85.741\n",
      "25600/54000\tLoss: 86.374\n",
      "28800/54000\tLoss: 86.048\n",
      "32000/54000\tLoss: 85.909\n",
      "35200/54000\tLoss: 86.233\n",
      "38400/54000\tLoss: 85.989\n",
      "41600/54000\tLoss: 85.770\n",
      "44800/54000\tLoss: 85.792\n",
      "48000/54000\tLoss: 85.656\n",
      "51200/54000\tLoss: 86.285\n",
      "Valid Loss: 85.373, Recon Error: 0.020\n",
      "85.37279534847178\n",
      "Epoch: 4 Average loss: 86.14 Valid loss: 85.37279534847178\tRecon Error:0.020\n",
      "0/54000\tLoss: 82.666\n",
      "3200/54000\tLoss: 85.185\n",
      "6400/54000\tLoss: 85.294\n",
      "9600/54000\tLoss: 85.008\n",
      "12800/54000\tLoss: 85.169\n",
      "16000/54000\tLoss: 85.092\n",
      "19200/54000\tLoss: 85.150\n",
      "22400/54000\tLoss: 85.379\n",
      "25600/54000\tLoss: 84.529\n",
      "28800/54000\tLoss: 85.098\n",
      "32000/54000\tLoss: 84.875\n",
      "35200/54000\tLoss: 84.314\n",
      "38400/54000\tLoss: 85.057\n",
      "41600/54000\tLoss: 84.631\n",
      "44800/54000\tLoss: 84.219\n",
      "48000/54000\tLoss: 84.966\n",
      "51200/54000\tLoss: 84.427\n",
      "Valid Loss: 84.315, Recon Error: 0.019\n",
      "84.31488515975627\n",
      "Epoch: 5 Average loss: 84.90 Valid loss: 84.31488515975627\tRecon Error:0.019\n",
      "0/54000\tLoss: 85.260\n",
      "3200/54000\tLoss: 84.581\n",
      "6400/54000\tLoss: 84.315\n",
      "9600/54000\tLoss: 84.259\n",
      "12800/54000\tLoss: 84.301\n",
      "16000/54000\tLoss: 83.668\n",
      "19200/54000\tLoss: 83.928\n",
      "22400/54000\tLoss: 84.255\n",
      "25600/54000\tLoss: 83.919\n",
      "28800/54000\tLoss: 83.983\n",
      "32000/54000\tLoss: 83.738\n",
      "35200/54000\tLoss: 84.121\n",
      "38400/54000\tLoss: 84.122\n",
      "41600/54000\tLoss: 84.403\n",
      "44800/54000\tLoss: 83.808\n",
      "48000/54000\tLoss: 84.172\n",
      "51200/54000\tLoss: 84.064\n",
      "Valid Loss: 83.654, Recon Error: 0.015\n",
      "83.65350569055435\n",
      "Epoch: 6 Average loss: 84.13 Valid loss: 83.65350569055435\tRecon Error:0.015\n",
      "0/54000\tLoss: 83.759\n",
      "3200/54000\tLoss: 83.746\n",
      "6400/54000\tLoss: 83.596\n",
      "9600/54000\tLoss: 83.507\n",
      "12800/54000\tLoss: 83.723\n",
      "16000/54000\tLoss: 83.588\n",
      "19200/54000\tLoss: 83.795\n",
      "22400/54000\tLoss: 83.729\n",
      "25600/54000\tLoss: 83.611\n",
      "28800/54000\tLoss: 83.583\n",
      "32000/54000\tLoss: 83.217\n",
      "35200/54000\tLoss: 83.276\n",
      "38400/54000\tLoss: 83.346\n",
      "41600/54000\tLoss: 83.010\n",
      "44800/54000\tLoss: 83.530\n",
      "48000/54000\tLoss: 83.517\n",
      "51200/54000\tLoss: 83.593\n",
      "Valid Loss: 83.419, Recon Error: 0.019\n",
      "83.41852399136158\n",
      "Epoch: 7 Average loss: 83.54 Valid loss: 83.41852399136158\tRecon Error:0.019\n",
      "0/54000\tLoss: 83.222\n",
      "3200/54000\tLoss: 83.057\n",
      "6400/54000\tLoss: 83.029\n",
      "9600/54000\tLoss: 83.038\n",
      "12800/54000\tLoss: 83.011\n",
      "16000/54000\tLoss: 82.810\n",
      "19200/54000\tLoss: 82.660\n",
      "22400/54000\tLoss: 82.972\n",
      "25600/54000\tLoss: 82.750\n",
      "28800/54000\tLoss: 83.043\n",
      "32000/54000\tLoss: 82.668\n",
      "35200/54000\tLoss: 82.768\n",
      "38400/54000\tLoss: 83.093\n",
      "41600/54000\tLoss: 82.830\n",
      "44800/54000\tLoss: 82.638\n",
      "48000/54000\tLoss: 82.764\n",
      "51200/54000\tLoss: 82.720\n",
      "Valid Loss: 82.588, Recon Error: 0.020\n",
      "82.58834522328478\n",
      "Epoch: 8 Average loss: 82.89 Valid loss: 82.58834522328478\tRecon Error:0.020\n",
      "0/54000\tLoss: 79.273\n",
      "3200/54000\tLoss: 82.864\n",
      "6400/54000\tLoss: 82.702\n",
      "9600/54000\tLoss: 82.395\n",
      "12800/54000\tLoss: 82.508\n",
      "16000/54000\tLoss: 82.183\n",
      "19200/54000\tLoss: 81.943\n",
      "22400/54000\tLoss: 82.457\n",
      "25600/54000\tLoss: 81.894\n",
      "28800/54000\tLoss: 81.692\n",
      "32000/54000\tLoss: 81.991\n",
      "35200/54000\tLoss: 81.972\n",
      "38400/54000\tLoss: 82.448\n",
      "41600/54000\tLoss: 82.142\n",
      "44800/54000\tLoss: 82.221\n",
      "48000/54000\tLoss: 81.642\n",
      "51200/54000\tLoss: 82.365\n",
      "Valid Loss: 81.868, Recon Error: 0.016\n",
      "81.86838669472553\n",
      "Epoch: 9 Average loss: 82.20 Valid loss: 81.86838669472553\tRecon Error:0.016\n",
      "0/54000\tLoss: 83.118\n",
      "3200/54000\tLoss: 81.546\n",
      "6400/54000\tLoss: 81.401\n",
      "9600/54000\tLoss: 81.787\n",
      "12800/54000\tLoss: 81.285\n",
      "16000/54000\tLoss: 81.901\n",
      "19200/54000\tLoss: 81.849\n",
      "22400/54000\tLoss: 81.369\n",
      "25600/54000\tLoss: 81.333\n",
      "28800/54000\tLoss: 81.243\n",
      "32000/54000\tLoss: 80.888\n",
      "35200/54000\tLoss: 81.439\n",
      "38400/54000\tLoss: 81.565\n",
      "41600/54000\tLoss: 81.165\n",
      "44800/54000\tLoss: 80.996\n",
      "48000/54000\tLoss: 81.430\n",
      "51200/54000\tLoss: 80.857\n",
      "Valid Loss: 80.926, Recon Error: 0.017\n",
      "80.92647990774601\n",
      "Epoch: 10 Average loss: 81.39 Valid loss: 80.92647990774601\tRecon Error:0.017\n",
      "0/54000\tLoss: 80.650\n",
      "3200/54000\tLoss: 81.012\n",
      "6400/54000\tLoss: 80.916\n",
      "9600/54000\tLoss: 81.276\n",
      "12800/54000\tLoss: 81.246\n",
      "16000/54000\tLoss: 81.128\n",
      "19200/54000\tLoss: 81.160\n",
      "22400/54000\tLoss: 81.122\n",
      "25600/54000\tLoss: 80.907\n",
      "28800/54000\tLoss: 80.658\n",
      "32000/54000\tLoss: 80.713\n",
      "35200/54000\tLoss: 80.746\n",
      "38400/54000\tLoss: 80.318\n",
      "41600/54000\tLoss: 80.678\n",
      "44800/54000\tLoss: 80.621\n",
      "48000/54000\tLoss: 80.233\n",
      "51200/54000\tLoss: 80.488\n",
      "Valid Loss: 79.877, Recon Error: 0.018\n",
      "79.87716837132231\n",
      "Epoch: 11 Average loss: 80.85 Valid loss: 79.87716837132231\tRecon Error:0.018\n",
      "0/54000\tLoss: 81.520\n",
      "3200/54000\tLoss: 80.433\n",
      "6400/54000\tLoss: 80.253\n",
      "9600/54000\tLoss: 80.311\n",
      "12800/54000\tLoss: 80.526\n",
      "16000/54000\tLoss: 80.000\n",
      "19200/54000\tLoss: 80.205\n",
      "22400/54000\tLoss: 80.508\n",
      "25600/54000\tLoss: 80.440\n",
      "28800/54000\tLoss: 80.365\n",
      "32000/54000\tLoss: 80.330\n",
      "35200/54000\tLoss: 79.921\n",
      "38400/54000\tLoss: 79.989\n",
      "41600/54000\tLoss: 79.820\n",
      "44800/54000\tLoss: 80.211\n",
      "48000/54000\tLoss: 79.657\n",
      "51200/54000\tLoss: 79.975\n",
      "Valid Loss: 79.678, Recon Error: 0.017\n",
      "79.67831437131191\n",
      "Epoch: 12 Average loss: 80.16 Valid loss: 79.67831437131191\tRecon Error:0.017\n",
      "0/54000\tLoss: 79.744\n",
      "3200/54000\tLoss: 79.752\n",
      "6400/54000\tLoss: 79.369\n",
      "9600/54000\tLoss: 79.544\n",
      "12800/54000\tLoss: 79.808\n",
      "16000/54000\tLoss: 80.055\n",
      "19200/54000\tLoss: 79.826\n",
      "22400/54000\tLoss: 79.907\n",
      "25600/54000\tLoss: 79.982\n",
      "28800/54000\tLoss: 79.951\n",
      "32000/54000\tLoss: 79.863\n",
      "35200/54000\tLoss: 79.230\n",
      "38400/54000\tLoss: 79.503\n",
      "41600/54000\tLoss: 79.530\n",
      "44800/54000\tLoss: 79.665\n",
      "48000/54000\tLoss: 79.417\n",
      "51200/54000\tLoss: 79.572\n",
      "Valid Loss: 79.644, Recon Error: 0.016\n",
      "79.64363317286714\n",
      "Epoch: 13 Average loss: 79.70 Valid loss: 79.64363317286714\tRecon Error:0.016\n",
      "0/54000\tLoss: 79.492\n",
      "3200/54000\tLoss: 79.787\n",
      "6400/54000\tLoss: 79.545\n",
      "9600/54000\tLoss: 79.400\n",
      "12800/54000\tLoss: 79.300\n",
      "16000/54000\tLoss: 79.418\n",
      "19200/54000\tLoss: 79.572\n",
      "22400/54000\tLoss: 79.408\n",
      "25600/54000\tLoss: 79.279\n",
      "28800/54000\tLoss: 79.210\n",
      "32000/54000\tLoss: 79.222\n",
      "35200/54000\tLoss: 79.393\n",
      "38400/54000\tLoss: 78.858\n",
      "41600/54000\tLoss: 79.468\n",
      "44800/54000\tLoss: 79.256\n",
      "48000/54000\tLoss: 78.964\n",
      "51200/54000\tLoss: 79.170\n",
      "Valid Loss: 79.117, Recon Error: 0.015\n",
      "79.11719569754094\n",
      "Epoch: 14 Average loss: 79.36 Valid loss: 79.11719569754094\tRecon Error:0.015\n",
      "0/54000\tLoss: 80.439\n",
      "3200/54000\tLoss: 79.587\n",
      "6400/54000\tLoss: 79.323\n",
      "9600/54000\tLoss: 79.330\n",
      "12800/54000\tLoss: 78.936\n",
      "16000/54000\tLoss: 78.350\n",
      "19200/54000\tLoss: 79.210\n",
      "22400/54000\tLoss: 79.127\n",
      "25600/54000\tLoss: 78.914\n",
      "28800/54000\tLoss: 78.978\n",
      "32000/54000\tLoss: 78.655\n",
      "35200/54000\tLoss: 78.607\n",
      "38400/54000\tLoss: 79.175\n",
      "41600/54000\tLoss: 79.318\n",
      "44800/54000\tLoss: 78.864\n",
      "48000/54000\tLoss: 79.080\n",
      "51200/54000\tLoss: 78.827\n",
      "Valid Loss: 78.864, Recon Error: 0.017\n",
      "78.86438540194897\n",
      "Epoch: 15 Average loss: 79.03 Valid loss: 78.86438540194897\tRecon Error:0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/54000\tLoss: 79.207\n",
      "3200/54000\tLoss: 78.320\n",
      "6400/54000\tLoss: 78.858\n",
      "9600/54000\tLoss: 78.754\n",
      "12800/54000\tLoss: 78.803\n",
      "16000/54000\tLoss: 78.871\n",
      "19200/54000\tLoss: 78.778\n",
      "22400/54000\tLoss: 78.699\n",
      "25600/54000\tLoss: 78.902\n",
      "28800/54000\tLoss: 78.777\n",
      "32000/54000\tLoss: 78.906\n",
      "35200/54000\tLoss: 78.998\n",
      "38400/54000\tLoss: 79.244\n",
      "41600/54000\tLoss: 78.801\n",
      "44800/54000\tLoss: 78.781\n",
      "48000/54000\tLoss: 78.821\n",
      "51200/54000\tLoss: 79.021\n",
      "Valid Loss: 78.996, Recon Error: 0.016\n",
      "78.9960331206626\n",
      "Epoch: 16 Average loss: 78.85 Valid loss: 78.9960331206626\tRecon Error:0.016\n",
      "0/54000\tLoss: 77.879\n",
      "3200/54000\tLoss: 78.525\n",
      "6400/54000\tLoss: 78.882\n",
      "9600/54000\tLoss: 78.785\n",
      "12800/54000\tLoss: 78.798\n",
      "16000/54000\tLoss: 78.653\n",
      "19200/54000\tLoss: 78.591\n",
      "22400/54000\tLoss: 78.614\n",
      "25600/54000\tLoss: 78.590\n",
      "28800/54000\tLoss: 78.818\n",
      "32000/54000\tLoss: 78.399\n",
      "35200/54000\tLoss: 78.532\n",
      "38400/54000\tLoss: 78.343\n",
      "41600/54000\tLoss: 78.253\n",
      "44800/54000\tLoss: 78.469\n",
      "48000/54000\tLoss: 77.863\n",
      "51200/54000\tLoss: 78.317\n",
      "Valid Loss: 78.798, Recon Error: 0.017\n",
      "78.79784709849257\n",
      "Epoch: 17 Average loss: 78.54 Valid loss: 78.79784709849257\tRecon Error:0.017\n",
      "0/54000\tLoss: 80.411\n",
      "3200/54000\tLoss: 78.308\n",
      "6400/54000\tLoss: 78.600\n",
      "9600/54000\tLoss: 78.901\n",
      "12800/54000\tLoss: 78.492\n",
      "16000/54000\tLoss: 78.494\n",
      "19200/54000\tLoss: 78.454\n",
      "22400/54000\tLoss: 78.307\n",
      "25600/54000\tLoss: 78.194\n",
      "28800/54000\tLoss: 78.601\n",
      "32000/54000\tLoss: 77.835\n",
      "35200/54000\tLoss: 78.546\n",
      "38400/54000\tLoss: 77.958\n",
      "41600/54000\tLoss: 78.125\n",
      "44800/54000\tLoss: 78.507\n",
      "48000/54000\tLoss: 77.813\n",
      "51200/54000\tLoss: 78.339\n",
      "Valid Loss: 78.118, Recon Error: 0.016\n",
      "78.11791383459213\n",
      "Epoch: 18 Average loss: 78.37 Valid loss: 78.11791383459213\tRecon Error:0.016\n",
      "0/54000\tLoss: 76.400\n",
      "3200/54000\tLoss: 77.957\n",
      "6400/54000\tLoss: 78.311\n",
      "9600/54000\tLoss: 78.079\n",
      "12800/54000\tLoss: 78.450\n",
      "16000/54000\tLoss: 78.196\n",
      "19200/54000\tLoss: 78.165\n",
      "22400/54000\tLoss: 78.175\n",
      "25600/54000\tLoss: 77.838\n",
      "28800/54000\tLoss: 78.340\n",
      "32000/54000\tLoss: 78.058\n",
      "35200/54000\tLoss: 77.923\n",
      "38400/54000\tLoss: 78.141\n",
      "41600/54000\tLoss: 78.059\n",
      "44800/54000\tLoss: 78.096\n",
      "48000/54000\tLoss: 77.791\n",
      "51200/54000\tLoss: 78.079\n",
      "Valid Loss: 77.910, Recon Error: 0.015\n",
      "77.91035469542159\n",
      "Epoch: 19 Average loss: 78.12 Valid loss: 77.91035469542159\tRecon Error:0.015\n",
      "0/54000\tLoss: 78.714\n",
      "3200/54000\tLoss: 78.284\n",
      "6400/54000\tLoss: 77.625\n",
      "9600/54000\tLoss: 77.788\n",
      "12800/54000\tLoss: 78.506\n",
      "16000/54000\tLoss: 77.967\n",
      "19200/54000\tLoss: 77.638\n",
      "22400/54000\tLoss: 78.298\n",
      "25600/54000\tLoss: 77.882\n",
      "28800/54000\tLoss: 77.573\n",
      "32000/54000\tLoss: 77.951\n",
      "35200/54000\tLoss: 78.092\n",
      "38400/54000\tLoss: 77.549\n",
      "41600/54000\tLoss: 77.903\n",
      "44800/54000\tLoss: 78.322\n",
      "48000/54000\tLoss: 77.607\n",
      "51200/54000\tLoss: 77.035\n",
      "Valid Loss: 77.564, Recon Error: 0.017\n",
      "77.5644782857692\n",
      "Epoch: 20 Average loss: 77.91 Valid loss: 77.5644782857692\tRecon Error:0.017\n",
      "0/54000\tLoss: 75.749\n",
      "3200/54000\tLoss: 77.841\n",
      "6400/54000\tLoss: 77.531\n",
      "9600/54000\tLoss: 77.435\n",
      "12800/54000\tLoss: 77.342\n",
      "16000/54000\tLoss: 77.623\n",
      "19200/54000\tLoss: 77.830\n",
      "22400/54000\tLoss: 77.632\n",
      "25600/54000\tLoss: 77.672\n",
      "28800/54000\tLoss: 77.412\n",
      "32000/54000\tLoss: 77.454\n",
      "35200/54000\tLoss: 77.284\n",
      "38400/54000\tLoss: 77.105\n",
      "41600/54000\tLoss: 77.464\n",
      "44800/54000\tLoss: 77.573\n",
      "48000/54000\tLoss: 77.298\n",
      "51200/54000\tLoss: 77.362\n",
      "Valid Loss: 77.097, Recon Error: 0.014\n",
      "77.09706302399331\n",
      "Epoch: 21 Average loss: 77.48 Valid loss: 77.09706302399331\tRecon Error:0.014\n",
      "0/54000\tLoss: 76.120\n",
      "3200/54000\tLoss: 77.687\n",
      "6400/54000\tLoss: 76.944\n",
      "9600/54000\tLoss: 77.282\n",
      "12800/54000\tLoss: 77.122\n",
      "16000/54000\tLoss: 77.396\n",
      "19200/54000\tLoss: 77.183\n",
      "22400/54000\tLoss: 77.462\n",
      "25600/54000\tLoss: 76.841\n",
      "28800/54000\tLoss: 76.961\n",
      "32000/54000\tLoss: 76.811\n",
      "35200/54000\tLoss: 77.149\n",
      "38400/54000\tLoss: 77.044\n",
      "41600/54000\tLoss: 77.377\n",
      "44800/54000\tLoss: 77.976\n",
      "48000/54000\tLoss: 77.519\n",
      "51200/54000\tLoss: 77.345\n",
      "Valid Loss: 77.197, Recon Error: 0.017\n",
      "77.19704128833527\n",
      "Epoch: 22 Average loss: 77.28 Valid loss: 77.19704128833527\tRecon Error:0.017\n",
      "0/54000\tLoss: 74.229\n",
      "3200/54000\tLoss: 77.164\n",
      "6400/54000\tLoss: 76.925\n",
      "9600/54000\tLoss: 76.834\n",
      "12800/54000\tLoss: 77.266\n",
      "16000/54000\tLoss: 77.089\n",
      "19200/54000\tLoss: 77.089\n",
      "22400/54000\tLoss: 77.479\n",
      "25600/54000\tLoss: 77.103\n",
      "28800/54000\tLoss: 77.309\n",
      "32000/54000\tLoss: 77.168\n",
      "35200/54000\tLoss: 76.838\n",
      "38400/54000\tLoss: 76.929\n",
      "41600/54000\tLoss: 77.306\n",
      "44800/54000\tLoss: 76.771\n",
      "48000/54000\tLoss: 76.900\n",
      "51200/54000\tLoss: 77.090\n",
      "Valid Loss: 76.662, Recon Error: 0.017\n",
      "76.66213250667491\n",
      "Epoch: 23 Average loss: 77.10 Valid loss: 76.66213250667491\tRecon Error:0.017\n",
      "0/54000\tLoss: 72.840\n",
      "3200/54000\tLoss: 76.855\n",
      "6400/54000\tLoss: 77.098\n",
      "9600/54000\tLoss: 76.800\n",
      "12800/54000\tLoss: 76.865\n",
      "16000/54000\tLoss: 76.527\n",
      "19200/54000\tLoss: 76.458\n",
      "22400/54000\tLoss: 76.744\n",
      "25600/54000\tLoss: 76.983\n",
      "28800/54000\tLoss: 76.919\n",
      "32000/54000\tLoss: 76.866\n",
      "35200/54000\tLoss: 76.700\n",
      "38400/54000\tLoss: 76.395\n",
      "41600/54000\tLoss: 76.950\n",
      "44800/54000\tLoss: 76.774\n",
      "48000/54000\tLoss: 76.815\n",
      "51200/54000\tLoss: 76.418\n",
      "Valid Loss: 76.443, Recon Error: 0.016\n",
      "76.44277101881961\n",
      "Epoch: 24 Average loss: 76.79 Valid loss: 76.44277101881961\tRecon Error:0.016\n",
      "0/54000\tLoss: 77.891\n",
      "3200/54000\tLoss: 76.380\n",
      "6400/54000\tLoss: 76.439\n",
      "9600/54000\tLoss: 76.619\n",
      "12800/54000\tLoss: 77.124\n",
      "16000/54000\tLoss: 76.335\n",
      "19200/54000\tLoss: 76.488\n",
      "22400/54000\tLoss: 76.164\n",
      "25600/54000\tLoss: 76.791\n",
      "28800/54000\tLoss: 76.617\n",
      "32000/54000\tLoss: 76.628\n",
      "35200/54000\tLoss: 76.667\n",
      "38400/54000\tLoss: 76.696\n",
      "41600/54000\tLoss: 76.872\n",
      "44800/54000\tLoss: 77.027\n",
      "48000/54000\tLoss: 76.547\n",
      "51200/54000\tLoss: 76.281\n",
      "Valid Loss: 76.708, Recon Error: 0.015\n",
      "76.70779102406603\n",
      "Epoch: 25 Average loss: 76.63 Valid loss: 76.70779102406603\tRecon Error:0.015\n",
      "0/54000\tLoss: 76.767\n",
      "3200/54000\tLoss: 76.867\n",
      "6400/54000\tLoss: 76.883\n",
      "9600/54000\tLoss: 76.593\n",
      "12800/54000\tLoss: 76.173\n",
      "16000/54000\tLoss: 76.949\n",
      "19200/54000\tLoss: 76.491\n",
      "22400/54000\tLoss: 76.393\n",
      "25600/54000\tLoss: 76.088\n",
      "28800/54000\tLoss: 75.973\n",
      "32000/54000\tLoss: 76.345\n",
      "35200/54000\tLoss: 76.485\n",
      "38400/54000\tLoss: 76.570\n",
      "41600/54000\tLoss: 76.713\n",
      "44800/54000\tLoss: 76.435\n",
      "48000/54000\tLoss: 76.693\n",
      "51200/54000\tLoss: 76.588\n",
      "Valid Loss: 76.430, Recon Error: 0.015\n",
      "76.42976590420338\n",
      "Epoch: 26 Average loss: 76.54 Valid loss: 76.42976590420338\tRecon Error:0.015\n",
      "0/54000\tLoss: 75.032\n",
      "3200/54000\tLoss: 76.209\n",
      "6400/54000\tLoss: 76.655\n",
      "9600/54000\tLoss: 76.268\n",
      "12800/54000\tLoss: 76.546\n",
      "16000/54000\tLoss: 76.282\n",
      "19200/54000\tLoss: 75.885\n",
      "22400/54000\tLoss: 76.678\n",
      "25600/54000\tLoss: 75.912\n",
      "28800/54000\tLoss: 76.123\n",
      "32000/54000\tLoss: 76.687\n",
      "35200/54000\tLoss: 76.105\n",
      "38400/54000\tLoss: 76.127\n",
      "41600/54000\tLoss: 76.295\n",
      "44800/54000\tLoss: 76.836\n",
      "48000/54000\tLoss: 76.052\n",
      "51200/54000\tLoss: 76.465\n",
      "Valid Loss: 76.527, Recon Error: 0.017\n",
      "76.52695554368039\n",
      "Epoch: 27 Average loss: 76.33 Valid loss: 76.52695554368039\tRecon Error:0.017\n",
      "0/54000\tLoss: 76.610\n",
      "3200/54000\tLoss: 76.599\n",
      "6400/54000\tLoss: 76.225\n",
      "9600/54000\tLoss: 76.632\n",
      "12800/54000\tLoss: 76.101\n",
      "16000/54000\tLoss: 76.018\n",
      "19200/54000\tLoss: 75.939\n",
      "22400/54000\tLoss: 76.274\n",
      "25600/54000\tLoss: 75.832\n",
      "28800/54000\tLoss: 75.916\n",
      "32000/54000\tLoss: 76.252\n",
      "35200/54000\tLoss: 76.201\n",
      "38400/54000\tLoss: 75.812\n",
      "41600/54000\tLoss: 76.401\n",
      "44800/54000\tLoss: 76.435\n",
      "48000/54000\tLoss: 75.832\n",
      "51200/54000\tLoss: 76.453\n",
      "Valid Loss: 76.171, Recon Error: 0.016\n",
      "76.17092603318234\n",
      "Epoch: 28 Average loss: 76.20 Valid loss: 76.17092603318234\tRecon Error:0.016\n",
      "0/54000\tLoss: 72.235\n",
      "3200/54000\tLoss: 75.839\n",
      "6400/54000\tLoss: 76.337\n",
      "9600/54000\tLoss: 76.057\n",
      "12800/54000\tLoss: 76.327\n",
      "16000/54000\tLoss: 76.144\n",
      "19200/54000\tLoss: 75.575\n",
      "22400/54000\tLoss: 75.819\n",
      "25600/54000\tLoss: 75.748\n",
      "28800/54000\tLoss: 76.103\n",
      "32000/54000\tLoss: 76.403\n",
      "35200/54000\tLoss: 75.951\n",
      "38400/54000\tLoss: 76.288\n",
      "41600/54000\tLoss: 76.013\n",
      "44800/54000\tLoss: 75.492\n",
      "48000/54000\tLoss: 75.716\n",
      "51200/54000\tLoss: 76.337\n",
      "Valid Loss: 76.067, Recon Error: 0.020\n",
      "76.06711480972615\n",
      "Epoch: 29 Average loss: 76.05 Valid loss: 76.06711480972615\tRecon Error:0.020\n",
      "0/54000\tLoss: 75.420\n",
      "3200/54000\tLoss: 76.042\n",
      "6400/54000\tLoss: 76.356\n",
      "9600/54000\tLoss: 75.931\n",
      "12800/54000\tLoss: 75.084\n",
      "16000/54000\tLoss: 75.947\n",
      "19200/54000\tLoss: 76.061\n",
      "22400/54000\tLoss: 75.681\n",
      "25600/54000\tLoss: 75.459\n",
      "28800/54000\tLoss: 75.602\n",
      "32000/54000\tLoss: 75.887\n",
      "35200/54000\tLoss: 75.858\n",
      "38400/54000\tLoss: 75.950\n",
      "41600/54000\tLoss: 75.325\n",
      "44800/54000\tLoss: 75.928\n",
      "48000/54000\tLoss: 76.088\n",
      "51200/54000\tLoss: 76.304\n",
      "Valid Loss: 75.769, Recon Error: 0.017\n",
      "75.76855687892183\n",
      "Epoch: 30 Average loss: 75.87 Valid loss: 75.76855687892183\tRecon Error:0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/54000\tLoss: 76.791\n",
      "3200/54000\tLoss: 75.885\n",
      "6400/54000\tLoss: 75.277\n",
      "9600/54000\tLoss: 75.743\n",
      "12800/54000\tLoss: 75.975\n",
      "16000/54000\tLoss: 75.890\n",
      "19200/54000\tLoss: 75.477\n",
      "22400/54000\tLoss: 75.923\n",
      "25600/54000\tLoss: 75.694\n",
      "28800/54000\tLoss: 76.147\n",
      "32000/54000\tLoss: 75.749\n",
      "35200/54000\tLoss: 75.845\n",
      "38400/54000\tLoss: 75.092\n",
      "41600/54000\tLoss: 76.084\n",
      "44800/54000\tLoss: 75.842\n",
      "48000/54000\tLoss: 75.584\n",
      "51200/54000\tLoss: 75.984\n",
      "Valid Loss: 75.733, Recon Error: 0.017\n",
      "75.73328789244307\n",
      "Epoch: 31 Average loss: 75.78 Valid loss: 75.73328789244307\tRecon Error:0.017\n",
      "0/54000\tLoss: 76.194\n",
      "3200/54000\tLoss: 75.444\n",
      "6400/54000\tLoss: 75.689\n",
      "9600/54000\tLoss: 75.646\n",
      "12800/54000\tLoss: 75.633\n",
      "16000/54000\tLoss: 75.680\n",
      "19200/54000\tLoss: 75.727\n",
      "22400/54000\tLoss: 75.464\n",
      "25600/54000\tLoss: 75.484\n",
      "28800/54000\tLoss: 75.740\n",
      "32000/54000\tLoss: 75.992\n",
      "35200/54000\tLoss: 75.509\n",
      "38400/54000\tLoss: 75.369\n",
      "41600/54000\tLoss: 75.582\n",
      "44800/54000\tLoss: 74.981\n",
      "48000/54000\tLoss: 75.237\n",
      "51200/54000\tLoss: 75.587\n",
      "Valid Loss: 75.620, Recon Error: 0.015\n",
      "75.62036611678752\n",
      "Epoch: 32 Average loss: 75.57 Valid loss: 75.62036611678752\tRecon Error:0.015\n",
      "0/54000\tLoss: 72.641\n",
      "3200/54000\tLoss: 75.423\n",
      "6400/54000\tLoss: 75.044\n",
      "9600/54000\tLoss: 75.614\n",
      "12800/54000\tLoss: 75.509\n",
      "16000/54000\tLoss: 75.914\n",
      "19200/54000\tLoss: 75.362\n",
      "22400/54000\tLoss: 75.391\n",
      "25600/54000\tLoss: 74.985\n",
      "28800/54000\tLoss: 75.339\n",
      "32000/54000\tLoss: 75.273\n",
      "35200/54000\tLoss: 75.324\n",
      "38400/54000\tLoss: 75.357\n",
      "41600/54000\tLoss: 75.372\n",
      "44800/54000\tLoss: 75.166\n",
      "48000/54000\tLoss: 75.184\n",
      "51200/54000\tLoss: 75.545\n",
      "Valid Loss: 75.303, Recon Error: 0.018\n",
      "75.3027698435682\n",
      "Epoch: 33 Average loss: 75.34 Valid loss: 75.3027698435682\tRecon Error:0.018\n",
      "0/54000\tLoss: 77.843\n",
      "3200/54000\tLoss: 75.392\n",
      "6400/54000\tLoss: 75.286\n",
      "9600/54000\tLoss: 74.996\n",
      "12800/54000\tLoss: 75.516\n",
      "16000/54000\tLoss: 74.637\n",
      "19200/54000\tLoss: 74.810\n",
      "22400/54000\tLoss: 74.984\n",
      "25600/54000\tLoss: 75.352\n",
      "28800/54000\tLoss: 75.283\n",
      "32000/54000\tLoss: 74.845\n",
      "35200/54000\tLoss: 75.062\n",
      "38400/54000\tLoss: 74.954\n",
      "41600/54000\tLoss: 75.188\n",
      "44800/54000\tLoss: 75.181\n",
      "48000/54000\tLoss: 75.256\n",
      "51200/54000\tLoss: 75.346\n",
      "Valid Loss: 75.419, Recon Error: 0.018\n",
      "75.41862528374854\n",
      "Epoch: 34 Average loss: 75.17 Valid loss: 75.41862528374854\tRecon Error:0.018\n",
      "0/54000\tLoss: 76.383\n",
      "3200/54000\tLoss: 74.892\n",
      "6400/54000\tLoss: 75.202\n",
      "9600/54000\tLoss: 74.869\n",
      "12800/54000\tLoss: 75.098\n",
      "16000/54000\tLoss: 75.294\n",
      "19200/54000\tLoss: 75.792\n",
      "22400/54000\tLoss: 75.513\n",
      "25600/54000\tLoss: 75.091\n",
      "28800/54000\tLoss: 74.992\n",
      "32000/54000\tLoss: 74.766\n",
      "35200/54000\tLoss: 74.963\n",
      "38400/54000\tLoss: 75.508\n",
      "41600/54000\tLoss: 75.219\n",
      "44800/54000\tLoss: 74.752\n",
      "48000/54000\tLoss: 75.117\n",
      "51200/54000\tLoss: 74.862\n",
      "Valid Loss: 75.268, Recon Error: 0.016\n",
      "75.26774175116357\n",
      "Epoch: 35 Average loss: 75.14 Valid loss: 75.26774175116357\tRecon Error:0.016\n",
      "0/54000\tLoss: 72.243\n",
      "3200/54000\tLoss: 74.910\n",
      "6400/54000\tLoss: 75.200\n",
      "9600/54000\tLoss: 74.789\n",
      "12800/54000\tLoss: 75.332\n",
      "16000/54000\tLoss: 75.179\n",
      "19200/54000\tLoss: 75.197\n",
      "22400/54000\tLoss: 74.710\n",
      "25600/54000\tLoss: 75.084\n",
      "28800/54000\tLoss: 75.018\n",
      "32000/54000\tLoss: 75.582\n",
      "35200/54000\tLoss: 74.442\n",
      "38400/54000\tLoss: 75.062\n",
      "41600/54000\tLoss: 75.411\n",
      "44800/54000\tLoss: 74.605\n",
      "48000/54000\tLoss: 75.052\n",
      "51200/54000\tLoss: 75.140\n",
      "Valid Loss: 74.929, Recon Error: 0.018\n",
      "74.92860940162171\n",
      "Epoch: 36 Average loss: 75.07 Valid loss: 74.92860940162171\tRecon Error:0.018\n",
      "0/54000\tLoss: 76.608\n",
      "3200/54000\tLoss: 74.672\n",
      "6400/54000\tLoss: 74.400\n",
      "9600/54000\tLoss: 74.930\n",
      "12800/54000\tLoss: 74.989\n",
      "16000/54000\tLoss: 75.026\n",
      "19200/54000\tLoss: 74.616\n",
      "22400/54000\tLoss: 75.392\n",
      "25600/54000\tLoss: 74.564\n",
      "28800/54000\tLoss: 75.570\n",
      "32000/54000\tLoss: 74.911\n",
      "35200/54000\tLoss: 74.993\n",
      "38400/54000\tLoss: 75.205\n",
      "41600/54000\tLoss: 74.535\n",
      "44800/54000\tLoss: 75.134\n",
      "48000/54000\tLoss: 74.761\n",
      "51200/54000\tLoss: 75.149\n",
      "Valid Loss: 74.967, Recon Error: 0.015\n",
      "74.96698087327023\n",
      "Epoch: 37 Average loss: 74.95 Valid loss: 74.96698087327023\tRecon Error:0.015\n",
      "0/54000\tLoss: 73.399\n",
      "3200/54000\tLoss: 75.247\n",
      "6400/54000\tLoss: 74.643\n",
      "9600/54000\tLoss: 74.620\n",
      "12800/54000\tLoss: 74.391\n",
      "16000/54000\tLoss: 74.895\n",
      "19200/54000\tLoss: 74.664\n",
      "22400/54000\tLoss: 74.716\n",
      "25600/54000\tLoss: 74.658\n",
      "28800/54000\tLoss: 74.727\n",
      "32000/54000\tLoss: 74.865\n",
      "35200/54000\tLoss: 74.551\n",
      "38400/54000\tLoss: 74.537\n",
      "41600/54000\tLoss: 74.485\n",
      "44800/54000\tLoss: 75.004\n",
      "48000/54000\tLoss: 74.884\n",
      "51200/54000\tLoss: 74.500\n",
      "Valid Loss: 74.798, Recon Error: 0.016\n",
      "74.79776333748026\n",
      "Epoch: 38 Average loss: 74.71 Valid loss: 74.79776333748026\tRecon Error:0.016\n",
      "0/54000\tLoss: 74.822\n",
      "3200/54000\tLoss: 74.111\n",
      "6400/54000\tLoss: 74.414\n",
      "9600/54000\tLoss: 75.171\n",
      "12800/54000\tLoss: 74.998\n",
      "16000/54000\tLoss: 74.837\n",
      "19200/54000\tLoss: 74.558\n",
      "22400/54000\tLoss: 74.305\n",
      "25600/54000\tLoss: 74.548\n",
      "28800/54000\tLoss: 74.876\n",
      "32000/54000\tLoss: 74.739\n",
      "35200/54000\tLoss: 74.860\n",
      "38400/54000\tLoss: 74.206\n",
      "41600/54000\tLoss: 74.916\n",
      "44800/54000\tLoss: 75.052\n",
      "48000/54000\tLoss: 74.623\n",
      "51200/54000\tLoss: 75.279\n",
      "Valid Loss: 75.005, Recon Error: 0.018\n",
      "75.00530867880963\n",
      "Epoch: 39 Average loss: 74.73 Valid loss: 75.00530867880963\tRecon Error:0.018\n",
      "0/54000\tLoss: 70.371\n",
      "3200/54000\tLoss: 74.791\n",
      "6400/54000\tLoss: 74.883\n",
      "9600/54000\tLoss: 74.559\n",
      "12800/54000\tLoss: 74.540\n",
      "16000/54000\tLoss: 74.724\n",
      "19200/54000\tLoss: 74.420\n",
      "22400/54000\tLoss: 74.694\n",
      "25600/54000\tLoss: 73.781\n",
      "28800/54000\tLoss: 74.669\n",
      "32000/54000\tLoss: 74.389\n",
      "35200/54000\tLoss: 74.544\n",
      "38400/54000\tLoss: 74.697\n",
      "41600/54000\tLoss: 74.545\n",
      "44800/54000\tLoss: 74.646\n",
      "48000/54000\tLoss: 74.905\n",
      "51200/54000\tLoss: 74.203\n",
      "Valid Loss: 74.737, Recon Error: 0.018\n",
      "74.7367923817736\n",
      "Epoch: 40 Average loss: 74.60 Valid loss: 74.7367923817736\tRecon Error:0.018\n",
      "0/54000\tLoss: 73.069\n",
      "3200/54000\tLoss: 74.582\n",
      "6400/54000\tLoss: 74.786\n",
      "9600/54000\tLoss: 74.659\n",
      "12800/54000\tLoss: 74.265\n",
      "16000/54000\tLoss: 74.247\n",
      "19200/54000\tLoss: 74.406\n",
      "22400/54000\tLoss: 75.148\n",
      "25600/54000\tLoss: 74.493\n",
      "28800/54000\tLoss: 74.568\n",
      "32000/54000\tLoss: 74.706\n",
      "35200/54000\tLoss: 74.289\n",
      "38400/54000\tLoss: 74.236\n",
      "41600/54000\tLoss: 74.708\n",
      "44800/54000\tLoss: 73.891\n",
      "48000/54000\tLoss: 74.624\n",
      "51200/54000\tLoss: 74.375\n",
      "Valid Loss: 74.585, Recon Error: 0.018\n",
      "74.5845532518752\n",
      "Epoch: 41 Average loss: 74.53 Valid loss: 74.5845532518752\tRecon Error:0.018\n",
      "0/54000\tLoss: 79.109\n",
      "3200/54000\tLoss: 74.997\n",
      "6400/54000\tLoss: 74.480\n",
      "9600/54000\tLoss: 73.868\n",
      "12800/54000\tLoss: 74.168\n",
      "16000/54000\tLoss: 74.452\n",
      "19200/54000\tLoss: 74.583\n",
      "22400/54000\tLoss: 74.105\n",
      "25600/54000\tLoss: 74.495\n",
      "28800/54000\tLoss: 74.193\n",
      "32000/54000\tLoss: 74.915\n",
      "35200/54000\tLoss: 74.361\n",
      "38400/54000\tLoss: 74.096\n",
      "41600/54000\tLoss: 74.151\n",
      "44800/54000\tLoss: 74.190\n",
      "48000/54000\tLoss: 74.727\n",
      "51200/54000\tLoss: 74.262\n",
      "Valid Loss: 74.419, Recon Error: 0.015\n",
      "74.41936663363842\n",
      "Epoch: 42 Average loss: 74.43 Valid loss: 74.41936663363842\tRecon Error:0.015\n",
      "0/54000\tLoss: 76.452\n",
      "3200/54000\tLoss: 74.157\n",
      "6400/54000\tLoss: 74.491\n",
      "9600/54000\tLoss: 74.415\n",
      "12800/54000\tLoss: 74.486\n",
      "16000/54000\tLoss: 74.209\n",
      "19200/54000\tLoss: 74.555\n",
      "22400/54000\tLoss: 74.561\n",
      "25600/54000\tLoss: 73.955\n",
      "28800/54000\tLoss: 73.875\n",
      "32000/54000\tLoss: 74.073\n",
      "35200/54000\tLoss: 74.170\n",
      "38400/54000\tLoss: 74.624\n",
      "41600/54000\tLoss: 73.956\n",
      "44800/54000\tLoss: 74.583\n",
      "48000/54000\tLoss: 74.234\n",
      "51200/54000\tLoss: 74.222\n",
      "Valid Loss: 74.278, Recon Error: 0.017\n",
      "74.27789964067175\n",
      "Epoch: 43 Average loss: 74.32 Valid loss: 74.27789964067175\tRecon Error:0.017\n",
      "0/54000\tLoss: 70.999\n",
      "3200/54000\tLoss: 73.923\n",
      "6400/54000\tLoss: 74.088\n",
      "9600/54000\tLoss: 73.968\n",
      "12800/54000\tLoss: 73.947\n",
      "16000/54000\tLoss: 74.377\n",
      "19200/54000\tLoss: 73.876\n",
      "22400/54000\tLoss: 74.721\n",
      "25600/54000\tLoss: 74.036\n",
      "28800/54000\tLoss: 74.102\n",
      "32000/54000\tLoss: 74.040\n",
      "35200/54000\tLoss: 74.199\n",
      "38400/54000\tLoss: 74.648\n",
      "41600/54000\tLoss: 74.361\n",
      "44800/54000\tLoss: 74.316\n",
      "48000/54000\tLoss: 74.120\n",
      "51200/54000\tLoss: 74.424\n",
      "Valid Loss: 74.588, Recon Error: 0.017\n",
      "74.58813460329746\n",
      "Epoch: 44 Average loss: 74.25 Valid loss: 74.58813460329746\tRecon Error:0.017\n",
      "0/54000\tLoss: 76.626\n",
      "3200/54000\tLoss: 74.693\n",
      "6400/54000\tLoss: 73.925\n",
      "9600/54000\tLoss: 74.474\n",
      "12800/54000\tLoss: 74.008\n",
      "16000/54000\tLoss: 74.402\n",
      "19200/54000\tLoss: 74.114\n",
      "22400/54000\tLoss: 74.062\n",
      "25600/54000\tLoss: 74.187\n",
      "28800/54000\tLoss: 73.419\n",
      "32000/54000\tLoss: 74.904\n",
      "35200/54000\tLoss: 74.450\n",
      "38400/54000\tLoss: 74.229\n",
      "41600/54000\tLoss: 74.255\n",
      "44800/54000\tLoss: 73.958\n",
      "48000/54000\tLoss: 74.271\n",
      "51200/54000\tLoss: 74.131\n",
      "Valid Loss: 74.203, Recon Error: 0.016\n",
      "74.20326492634226\n",
      "Epoch: 45 Average loss: 74.24 Valid loss: 74.20326492634226\tRecon Error:0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/54000\tLoss: 71.274\n",
      "3200/54000\tLoss: 74.176\n",
      "6400/54000\tLoss: 73.892\n",
      "9600/54000\tLoss: 73.497\n",
      "12800/54000\tLoss: 74.498\n",
      "16000/54000\tLoss: 73.808\n",
      "19200/54000\tLoss: 74.477\n",
      "22400/54000\tLoss: 73.690\n",
      "25600/54000\tLoss: 74.082\n",
      "28800/54000\tLoss: 74.158\n",
      "32000/54000\tLoss: 74.523\n",
      "35200/54000\tLoss: 74.312\n",
      "38400/54000\tLoss: 74.238\n",
      "41600/54000\tLoss: 73.933\n",
      "44800/54000\tLoss: 74.157\n",
      "48000/54000\tLoss: 73.520\n",
      "51200/54000\tLoss: 74.224\n",
      "Valid Loss: 74.282, Recon Error: 0.019\n",
      "74.28212656873337\n",
      "Epoch: 46 Average loss: 74.10 Valid loss: 74.28212656873337\tRecon Error:0.019\n",
      "0/54000\tLoss: 74.198\n",
      "3200/54000\tLoss: 73.980\n",
      "6400/54000\tLoss: 74.195\n",
      "9600/54000\tLoss: 74.191\n",
      "12800/54000\tLoss: 74.180\n",
      "16000/54000\tLoss: 73.974\n",
      "19200/54000\tLoss: 73.736\n",
      "22400/54000\tLoss: 73.826\n",
      "25600/54000\tLoss: 73.840\n",
      "28800/54000\tLoss: 73.510\n",
      "32000/54000\tLoss: 74.303\n",
      "35200/54000\tLoss: 73.846\n",
      "38400/54000\tLoss: 73.781\n",
      "41600/54000\tLoss: 73.728\n",
      "44800/54000\tLoss: 74.403\n",
      "48000/54000\tLoss: 74.538\n",
      "51200/54000\tLoss: 74.097\n",
      "Valid Loss: 74.172, Recon Error: 0.015\n",
      "74.17181794186855\n",
      "Epoch: 47 Average loss: 74.04 Valid loss: 74.17181794186855\tRecon Error:0.015\n",
      "0/54000\tLoss: 76.146\n",
      "3200/54000\tLoss: 74.006\n",
      "6400/54000\tLoss: 73.563\n",
      "9600/54000\tLoss: 73.538\n",
      "12800/54000\tLoss: 74.151\n",
      "16000/54000\tLoss: 74.261\n",
      "19200/54000\tLoss: 73.850\n",
      "22400/54000\tLoss: 73.823\n",
      "25600/54000\tLoss: 74.014\n",
      "28800/54000\tLoss: 74.459\n",
      "32000/54000\tLoss: 73.831\n",
      "35200/54000\tLoss: 74.004\n",
      "38400/54000\tLoss: 73.501\n",
      "41600/54000\tLoss: 74.430\n",
      "44800/54000\tLoss: 73.748\n",
      "48000/54000\tLoss: 73.927\n",
      "51200/54000\tLoss: 73.533\n",
      "Valid Loss: 73.936, Recon Error: 0.017\n",
      "73.93564045682866\n",
      "Epoch: 48 Average loss: 73.95 Valid loss: 73.93564045682866\tRecon Error:0.017\n",
      "0/54000\tLoss: 74.602\n",
      "3200/54000\tLoss: 73.826\n",
      "6400/54000\tLoss: 74.041\n",
      "9600/54000\tLoss: 73.647\n",
      "12800/54000\tLoss: 73.573\n",
      "16000/54000\tLoss: 73.705\n",
      "19200/54000\tLoss: 73.825\n",
      "22400/54000\tLoss: 73.981\n",
      "25600/54000\tLoss: 73.700\n",
      "28800/54000\tLoss: 73.529\n",
      "32000/54000\tLoss: 73.863\n",
      "35200/54000\tLoss: 74.001\n",
      "38400/54000\tLoss: 73.605\n",
      "41600/54000\tLoss: 73.546\n",
      "44800/54000\tLoss: 74.258\n",
      "48000/54000\tLoss: 73.942\n",
      "51200/54000\tLoss: 74.283\n",
      "Valid Loss: 73.609, Recon Error: 0.017\n",
      "73.60863048472304\n",
      "Epoch: 49 Average loss: 73.86 Valid loss: 73.60863048472304\tRecon Error:0.017\n",
      "0/54000\tLoss: 75.042\n",
      "3200/54000\tLoss: 74.035\n",
      "6400/54000\tLoss: 73.656\n",
      "9600/54000\tLoss: 73.920\n",
      "12800/54000\tLoss: 73.628\n",
      "16000/54000\tLoss: 73.254\n",
      "19200/54000\tLoss: 73.835\n",
      "22400/54000\tLoss: 73.991\n",
      "25600/54000\tLoss: 73.862\n",
      "28800/54000\tLoss: 73.857\n",
      "32000/54000\tLoss: 74.220\n",
      "35200/54000\tLoss: 73.908\n",
      "38400/54000\tLoss: 74.002\n",
      "41600/54000\tLoss: 73.534\n",
      "44800/54000\tLoss: 74.222\n",
      "48000/54000\tLoss: 73.522\n",
      "51200/54000\tLoss: 73.298\n",
      "Valid Loss: 74.147, Recon Error: 0.016\n",
      "74.146896605796\n",
      "Epoch: 50 Average loss: 73.82 Valid loss: 74.146896605796\tRecon Error:0.016\n",
      "0/54000\tLoss: 74.082\n",
      "3200/54000\tLoss: 73.175\n",
      "6400/54000\tLoss: 73.881\n",
      "9600/54000\tLoss: 73.813\n",
      "12800/54000\tLoss: 73.781\n",
      "16000/54000\tLoss: 73.245\n",
      "19200/54000\tLoss: 73.861\n",
      "22400/54000\tLoss: 74.070\n",
      "25600/54000\tLoss: 73.585\n",
      "28800/54000\tLoss: 73.659\n",
      "32000/54000\tLoss: 74.313\n",
      "35200/54000\tLoss: 73.482\n",
      "38400/54000\tLoss: 73.366\n",
      "41600/54000\tLoss: 73.721\n",
      "44800/54000\tLoss: 73.485\n",
      "48000/54000\tLoss: 73.509\n",
      "51200/54000\tLoss: 73.837\n",
      "Valid Loss: 73.606, Recon Error: 0.016\n",
      "73.6063587107557\n",
      "Epoch: 51 Average loss: 73.73 Valid loss: 73.6063587107557\tRecon Error:0.016\n",
      "0/54000\tLoss: 76.414\n",
      "3200/54000\tLoss: 73.395\n",
      "6400/54000\tLoss: 74.090\n",
      "9600/54000\tLoss: 73.188\n",
      "12800/54000\tLoss: 73.296\n",
      "16000/54000\tLoss: 73.594\n",
      "19200/54000\tLoss: 73.865\n",
      "22400/54000\tLoss: 73.741\n",
      "25600/54000\tLoss: 73.895\n",
      "28800/54000\tLoss: 73.335\n",
      "32000/54000\tLoss: 73.691\n",
      "35200/54000\tLoss: 73.650\n",
      "38400/54000\tLoss: 73.476\n",
      "41600/54000\tLoss: 73.663\n",
      "44800/54000\tLoss: 73.911\n",
      "48000/54000\tLoss: 73.851\n",
      "51200/54000\tLoss: 73.547\n",
      "Valid Loss: 73.731, Recon Error: 0.014\n",
      "73.73085257347594\n",
      "Epoch: 52 Average loss: 73.64 Valid loss: 73.73085257347594\tRecon Error:0.014\n",
      "0/54000\tLoss: 71.603\n",
      "3200/54000\tLoss: 73.375\n",
      "6400/54000\tLoss: 73.237\n",
      "9600/54000\tLoss: 73.409\n",
      "12800/54000\tLoss: 72.730\n",
      "16000/54000\tLoss: 73.101\n",
      "19200/54000\tLoss: 73.344\n",
      "22400/54000\tLoss: 73.268\n",
      "25600/54000\tLoss: 73.313\n",
      "28800/54000\tLoss: 73.693\n",
      "32000/54000\tLoss: 73.224\n",
      "35200/54000\tLoss: 72.952\n",
      "38400/54000\tLoss: 73.833\n",
      "41600/54000\tLoss: 73.295\n",
      "44800/54000\tLoss: 73.633\n",
      "48000/54000\tLoss: 73.768\n",
      "51200/54000\tLoss: 73.934\n",
      "Valid Loss: 73.690, Recon Error: 0.017\n",
      "73.6896398016747\n",
      "Epoch: 53 Average loss: 73.42 Valid loss: 73.6896398016747\tRecon Error:0.017\n",
      "0/54000\tLoss: 73.754\n",
      "3200/54000\tLoss: 72.909\n",
      "6400/54000\tLoss: 73.707\n",
      "9600/54000\tLoss: 73.015\n",
      "12800/54000\tLoss: 73.171\n",
      "16000/54000\tLoss: 73.510\n",
      "19200/54000\tLoss: 73.170\n",
      "22400/54000\tLoss: 73.433\n",
      "25600/54000\tLoss: 72.834\n",
      "28800/54000\tLoss: 72.494\n",
      "32000/54000\tLoss: 73.527\n",
      "35200/54000\tLoss: 73.406\n",
      "38400/54000\tLoss: 73.942\n",
      "41600/54000\tLoss: 73.162\n",
      "44800/54000\tLoss: 73.273\n",
      "48000/54000\tLoss: 73.623\n",
      "51200/54000\tLoss: 73.575\n",
      "Valid Loss: 73.318, Recon Error: 0.016\n",
      "73.31822172124335\n",
      "Epoch: 54 Average loss: 73.32 Valid loss: 73.31822172124335\tRecon Error:0.016\n",
      "0/54000\tLoss: 71.565\n",
      "3200/54000\tLoss: 73.300\n",
      "6400/54000\tLoss: 72.842\n",
      "9600/54000\tLoss: 73.494\n",
      "12800/54000\tLoss: 73.342\n",
      "16000/54000\tLoss: 73.370\n",
      "19200/54000\tLoss: 73.376\n",
      "22400/54000\tLoss: 73.100\n",
      "25600/54000\tLoss: 73.302\n",
      "28800/54000\tLoss: 73.227\n",
      "32000/54000\tLoss: 73.234\n",
      "35200/54000\tLoss: 73.279\n",
      "38400/54000\tLoss: 73.681\n",
      "41600/54000\tLoss: 72.979\n",
      "44800/54000\tLoss: 73.278\n",
      "48000/54000\tLoss: 73.336\n",
      "51200/54000\tLoss: 73.518\n",
      "Valid Loss: 73.521, Recon Error: 0.016\n",
      "73.52050334849257\n",
      "Epoch: 55 Average loss: 73.31 Valid loss: 73.52050334849257\tRecon Error:0.016\n",
      "0/54000\tLoss: 73.519\n",
      "3200/54000\tLoss: 73.467\n",
      "6400/54000\tLoss: 73.329\n",
      "9600/54000\tLoss: 73.646\n",
      "12800/54000\tLoss: 72.950\n",
      "16000/54000\tLoss: 73.502\n",
      "19200/54000\tLoss: 72.937\n",
      "22400/54000\tLoss: 73.116\n",
      "25600/54000\tLoss: 73.309\n",
      "28800/54000\tLoss: 73.159\n",
      "32000/54000\tLoss: 73.601\n",
      "35200/54000\tLoss: 73.312\n",
      "38400/54000\tLoss: 73.668\n",
      "41600/54000\tLoss: 73.100\n",
      "44800/54000\tLoss: 72.971\n",
      "48000/54000\tLoss: 72.626\n",
      "51200/54000\tLoss: 72.946\n",
      "Valid Loss: 73.620, Recon Error: 0.016\n",
      "73.62001678791452\n",
      "Epoch: 56 Average loss: 73.21 Valid loss: 73.62001678791452\tRecon Error:0.016\n",
      "0/54000\tLoss: 74.843\n",
      "3200/54000\tLoss: 73.446\n",
      "6400/54000\tLoss: 73.128\n",
      "9600/54000\tLoss: 73.037\n",
      "12800/54000\tLoss: 72.641\n",
      "16000/54000\tLoss: 72.748\n",
      "19200/54000\tLoss: 73.031\n",
      "22400/54000\tLoss: 72.977\n",
      "25600/54000\tLoss: 72.595\n",
      "28800/54000\tLoss: 73.286\n",
      "32000/54000\tLoss: 72.816\n",
      "35200/54000\tLoss: 73.423\n",
      "38400/54000\tLoss: 72.970\n",
      "41600/54000\tLoss: 72.761\n",
      "44800/54000\tLoss: 73.251\n",
      "48000/54000\tLoss: 73.192\n",
      "51200/54000\tLoss: 73.128\n",
      "Valid Loss: 73.046, Recon Error: 0.015\n",
      "73.04622796241273\n",
      "Epoch: 57 Average loss: 73.05 Valid loss: 73.04622796241273\tRecon Error:0.015\n",
      "0/54000\tLoss: 74.783\n",
      "3200/54000\tLoss: 72.626\n",
      "6400/54000\tLoss: 72.834\n",
      "9600/54000\tLoss: 73.007\n",
      "12800/54000\tLoss: 73.129\n",
      "16000/54000\tLoss: 72.677\n",
      "19200/54000\tLoss: 73.215\n",
      "22400/54000\tLoss: 72.945\n",
      "25600/54000\tLoss: 72.831\n",
      "28800/54000\tLoss: 72.816\n",
      "32000/54000\tLoss: 72.840\n",
      "35200/54000\tLoss: 72.725\n",
      "38400/54000\tLoss: 72.374\n",
      "41600/54000\tLoss: 73.225\n",
      "44800/54000\tLoss: 72.855\n",
      "48000/54000\tLoss: 72.986\n",
      "51200/54000\tLoss: 72.353\n",
      "Valid Loss: 73.286, Recon Error: 0.015\n",
      "73.28578697366918\n",
      "Epoch: 58 Average loss: 72.88 Valid loss: 73.28578697366918\tRecon Error:0.015\n",
      "0/54000\tLoss: 71.910\n",
      "3200/54000\tLoss: 72.782\n",
      "6400/54000\tLoss: 72.214\n",
      "9600/54000\tLoss: 72.442\n",
      "12800/54000\tLoss: 72.313\n",
      "16000/54000\tLoss: 73.113\n",
      "19200/54000\tLoss: 72.741\n",
      "22400/54000\tLoss: 72.498\n",
      "25600/54000\tLoss: 72.754\n",
      "28800/54000\tLoss: 72.842\n",
      "32000/54000\tLoss: 72.854\n",
      "35200/54000\tLoss: 72.974\n",
      "38400/54000\tLoss: 72.721\n",
      "41600/54000\tLoss: 72.787\n",
      "44800/54000\tLoss: 72.788\n",
      "48000/54000\tLoss: 72.434\n",
      "51200/54000\tLoss: 72.111\n",
      "Valid Loss: 72.726, Recon Error: 0.015\n",
      "72.72552774307576\n",
      "Epoch: 59 Average loss: 72.67 Valid loss: 72.72552774307576\tRecon Error:0.015\n",
      "0/54000\tLoss: 74.628\n",
      "3200/54000\tLoss: 72.975\n",
      "6400/54000\tLoss: 71.938\n",
      "9600/54000\tLoss: 72.871\n",
      "12800/54000\tLoss: 72.547\n",
      "16000/54000\tLoss: 72.667\n",
      "19200/54000\tLoss: 72.281\n",
      "22400/54000\tLoss: 72.421\n",
      "25600/54000\tLoss: 72.827\n",
      "28800/54000\tLoss: 71.997\n",
      "32000/54000\tLoss: 72.938\n",
      "35200/54000\tLoss: 72.449\n",
      "38400/54000\tLoss: 72.204\n",
      "41600/54000\tLoss: 73.071\n",
      "44800/54000\tLoss: 72.382\n",
      "48000/54000\tLoss: 72.627\n",
      "51200/54000\tLoss: 72.251\n",
      "Valid Loss: 72.423, Recon Error: 0.015\n",
      "72.42349015905502\n",
      "Epoch: 60 Average loss: 72.53 Valid loss: 72.42349015905502\tRecon Error:0.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/54000\tLoss: 70.873\n",
      "3200/54000\tLoss: 72.550\n",
      "6400/54000\tLoss: 72.385\n",
      "9600/54000\tLoss: 73.004\n",
      "12800/54000\tLoss: 72.389\n",
      "16000/54000\tLoss: 72.276\n",
      "19200/54000\tLoss: 72.625\n",
      "22400/54000\tLoss: 72.091\n",
      "25600/54000\tLoss: 72.328\n",
      "28800/54000\tLoss: 72.244\n",
      "32000/54000\tLoss: 72.312\n",
      "35200/54000\tLoss: 72.121\n",
      "38400/54000\tLoss: 72.353\n",
      "41600/54000\tLoss: 71.881\n",
      "44800/54000\tLoss: 72.548\n",
      "48000/54000\tLoss: 72.611\n",
      "51200/54000\tLoss: 72.719\n",
      "Valid Loss: 72.795, Recon Error: 0.014\n",
      "72.79524742288793\n",
      "Epoch: 61 Average loss: 72.43 Valid loss: 72.79524742288793\tRecon Error:0.014\n",
      "0/54000\tLoss: 70.575\n",
      "3200/54000\tLoss: 72.426\n",
      "6400/54000\tLoss: 72.332\n",
      "9600/54000\tLoss: 71.849\n",
      "12800/54000\tLoss: 72.143\n",
      "16000/54000\tLoss: 72.001\n",
      "19200/54000\tLoss: 72.311\n",
      "22400/54000\tLoss: 72.219\n",
      "25600/54000\tLoss: 72.125\n",
      "28800/54000\tLoss: 73.108\n",
      "32000/54000\tLoss: 72.500\n",
      "35200/54000\tLoss: 72.348\n",
      "38400/54000\tLoss: 71.685\n",
      "41600/54000\tLoss: 72.672\n",
      "44800/54000\tLoss: 72.420\n",
      "48000/54000\tLoss: 71.868\n",
      "51200/54000\tLoss: 72.316\n",
      "Valid Loss: 72.415, Recon Error: 0.013\n",
      "72.41514067954205\n",
      "Epoch: 62 Average loss: 72.28 Valid loss: 72.41514067954205\tRecon Error:0.013\n",
      "0/54000\tLoss: 71.815\n",
      "3200/54000\tLoss: 72.244\n",
      "6400/54000\tLoss: 72.115\n",
      "9600/54000\tLoss: 72.813\n",
      "12800/54000\tLoss: 72.113\n",
      "16000/54000\tLoss: 72.012\n",
      "19200/54000\tLoss: 72.313\n",
      "22400/54000\tLoss: 72.313\n",
      "25600/54000\tLoss: 72.163\n",
      "28800/54000\tLoss: 72.164\n",
      "32000/54000\tLoss: 71.755\n",
      "35200/54000\tLoss: 72.341\n",
      "38400/54000\tLoss: 72.143\n",
      "41600/54000\tLoss: 72.020\n",
      "44800/54000\tLoss: 72.589\n",
      "48000/54000\tLoss: 72.042\n",
      "51200/54000\tLoss: 71.951\n",
      "Valid Loss: 72.488, Recon Error: 0.016\n",
      "72.48816128994557\n",
      "Epoch: 63 Average loss: 72.22 Valid loss: 72.48816128994557\tRecon Error:0.016\n",
      "0/54000\tLoss: 70.804\n",
      "3200/54000\tLoss: 72.141\n",
      "6400/54000\tLoss: 72.101\n",
      "9600/54000\tLoss: 71.712\n",
      "12800/54000\tLoss: 72.070\n",
      "16000/54000\tLoss: 72.487\n",
      "19200/54000\tLoss: 72.393\n",
      "22400/54000\tLoss: 72.044\n",
      "25600/54000\tLoss: 72.282\n",
      "28800/54000\tLoss: 71.798\n",
      "32000/54000\tLoss: 71.950\n",
      "35200/54000\tLoss: 72.632\n",
      "38400/54000\tLoss: 72.136\n",
      "41600/54000\tLoss: 71.613\n",
      "44800/54000\tLoss: 72.178\n",
      "48000/54000\tLoss: 72.527\n",
      "51200/54000\tLoss: 72.546\n",
      "Valid Loss: 72.612, Recon Error: 0.015\n",
      "72.61216435533889\n",
      "Epoch: 64 Average loss: 72.21 Valid loss: 72.61216435533889\tRecon Error:0.015\n",
      "0/54000\tLoss: 73.212\n",
      "3200/54000\tLoss: 71.830\n",
      "6400/54000\tLoss: 71.989\n",
      "9600/54000\tLoss: 71.922\n",
      "12800/54000\tLoss: 71.592\n",
      "16000/54000\tLoss: 71.779\n",
      "19200/54000\tLoss: 72.114\n",
      "22400/54000\tLoss: 71.545\n",
      "25600/54000\tLoss: 71.859\n",
      "28800/54000\tLoss: 71.651\n",
      "32000/54000\tLoss: 72.088\n",
      "35200/54000\tLoss: 71.992\n",
      "38400/54000\tLoss: 71.701\n",
      "41600/54000\tLoss: 72.127\n",
      "44800/54000\tLoss: 72.175\n",
      "48000/54000\tLoss: 72.647\n",
      "51200/54000\tLoss: 72.018\n",
      "Valid Loss: 72.303, Recon Error: 0.016\n",
      "72.30258917301259\n",
      "Epoch: 65 Average loss: 71.97 Valid loss: 72.30258917301259\tRecon Error:0.016\n",
      "0/54000\tLoss: 71.560\n",
      "3200/54000\tLoss: 71.954\n",
      "6400/54000\tLoss: 71.369\n",
      "9600/54000\tLoss: 71.661\n",
      "12800/54000\tLoss: 72.239\n",
      "16000/54000\tLoss: 71.737\n",
      "19200/54000\tLoss: 72.096\n",
      "22400/54000\tLoss: 71.898\n",
      "25600/54000\tLoss: 71.941\n",
      "28800/54000\tLoss: 71.536\n",
      "32000/54000\tLoss: 71.782\n",
      "35200/54000\tLoss: 71.700\n",
      "38400/54000\tLoss: 71.788\n",
      "41600/54000\tLoss: 72.149\n",
      "44800/54000\tLoss: 71.518\n",
      "48000/54000\tLoss: 71.879\n",
      "51200/54000\tLoss: 71.942\n",
      "Valid Loss: 72.483, Recon Error: 0.016\n",
      "72.48328221097906\n",
      "Epoch: 66 Average loss: 71.88 Valid loss: 72.48328221097906\tRecon Error:0.016\n",
      "0/54000\tLoss: 72.878\n",
      "3200/54000\tLoss: 71.793\n",
      "6400/54000\tLoss: 71.661\n",
      "9600/54000\tLoss: 71.958\n",
      "12800/54000\tLoss: 71.836\n",
      "16000/54000\tLoss: 71.689\n",
      "19200/54000\tLoss: 72.038\n",
      "22400/54000\tLoss: 71.775\n",
      "25600/54000\tLoss: 72.085\n",
      "28800/54000\tLoss: 71.534\n",
      "32000/54000\tLoss: 72.111\n",
      "35200/54000\tLoss: 71.960\n",
      "38400/54000\tLoss: 71.838\n",
      "41600/54000\tLoss: 71.921\n",
      "44800/54000\tLoss: 71.888\n",
      "48000/54000\tLoss: 71.738\n",
      "51200/54000\tLoss: 71.401\n",
      "Valid Loss: 71.969, Recon Error: 0.016\n",
      "71.96867963101002\n",
      "Epoch: 67 Average loss: 71.83 Valid loss: 71.96867963101002\tRecon Error:0.016\n",
      "0/54000\tLoss: 71.578\n",
      "3200/54000\tLoss: 72.031\n",
      "6400/54000\tLoss: 71.715\n",
      "9600/54000\tLoss: 71.893\n",
      "12800/54000\tLoss: 71.836\n",
      "16000/54000\tLoss: 71.084\n",
      "19200/54000\tLoss: 71.849\n",
      "22400/54000\tLoss: 71.401\n",
      "25600/54000\tLoss: 71.867\n",
      "28800/54000\tLoss: 71.933\n",
      "32000/54000\tLoss: 71.814\n",
      "35200/54000\tLoss: 71.967\n",
      "38400/54000\tLoss: 71.481\n",
      "41600/54000\tLoss: 72.010\n",
      "44800/54000\tLoss: 71.571\n",
      "48000/54000\tLoss: 71.469\n",
      "51200/54000\tLoss: 71.955\n",
      "Valid Loss: 72.031, Recon Error: 0.015\n",
      "72.0313048667096\n",
      "Epoch: 68 Average loss: 71.76 Valid loss: 72.0313048667096\tRecon Error:0.015\n",
      "0/54000\tLoss: 74.277\n",
      "3200/54000\tLoss: 71.051\n",
      "6400/54000\tLoss: 71.652\n",
      "9600/54000\tLoss: 72.040\n",
      "12800/54000\tLoss: 71.376\n",
      "16000/54000\tLoss: 72.404\n",
      "19200/54000\tLoss: 72.049\n",
      "22400/54000\tLoss: 72.058\n",
      "25600/54000\tLoss: 71.857\n",
      "28800/54000\tLoss: 71.409\n",
      "32000/54000\tLoss: 71.713\n",
      "35200/54000\tLoss: 72.458\n",
      "38400/54000\tLoss: 71.602\n",
      "41600/54000\tLoss: 71.446\n",
      "44800/54000\tLoss: 71.865\n",
      "48000/54000\tLoss: 72.275\n",
      "51200/54000\tLoss: 71.940\n",
      "Valid Loss: 72.110, Recon Error: 0.017\n",
      "72.11020140952252\n",
      "Epoch: 69 Average loss: 71.80 Valid loss: 72.11020140952252\tRecon Error:0.017\n",
      "0/54000\tLoss: 73.191\n",
      "3200/54000\tLoss: 72.100\n",
      "6400/54000\tLoss: 71.825\n",
      "9600/54000\tLoss: 71.573\n",
      "12800/54000\tLoss: 71.932\n",
      "16000/54000\tLoss: 71.630\n",
      "19200/54000\tLoss: 71.941\n",
      "22400/54000\tLoss: 71.311\n",
      "25600/54000\tLoss: 71.502\n",
      "28800/54000\tLoss: 71.764\n",
      "32000/54000\tLoss: 71.595\n",
      "35200/54000\tLoss: 71.141\n",
      "38400/54000\tLoss: 71.538\n",
      "41600/54000\tLoss: 71.599\n",
      "44800/54000\tLoss: 71.537\n",
      "48000/54000\tLoss: 72.067\n",
      "51200/54000\tLoss: 72.015\n",
      "Valid Loss: 71.901, Recon Error: 0.013\n",
      "71.90055392650848\n",
      "Epoch: 70 Average loss: 71.72 Valid loss: 71.90055392650848\tRecon Error:0.013\n",
      "0/54000\tLoss: 72.070\n",
      "3200/54000\tLoss: 72.131\n",
      "6400/54000\tLoss: 71.649\n",
      "9600/54000\tLoss: 71.184\n",
      "12800/54000\tLoss: 72.051\n",
      "16000/54000\tLoss: 71.485\n",
      "19200/54000\tLoss: 71.008\n",
      "22400/54000\tLoss: 71.326\n",
      "25600/54000\tLoss: 71.513\n",
      "28800/54000\tLoss: 71.674\n",
      "32000/54000\tLoss: 71.657\n",
      "35200/54000\tLoss: 71.906\n",
      "38400/54000\tLoss: 71.858\n",
      "41600/54000\tLoss: 71.681\n",
      "44800/54000\tLoss: 71.778\n",
      "48000/54000\tLoss: 71.955\n",
      "51200/54000\tLoss: 71.525\n",
      "Valid Loss: 72.266, Recon Error: 0.017\n",
      "72.266037230796\n",
      "Epoch: 71 Average loss: 71.68 Valid loss: 72.266037230796\tRecon Error:0.017\n",
      "0/54000\tLoss: 71.663\n",
      "3200/54000\tLoss: 71.966\n",
      "6400/54000\tLoss: 71.430\n",
      "9600/54000\tLoss: 71.106\n",
      "12800/54000\tLoss: 71.579\n",
      "16000/54000\tLoss: 71.730\n",
      "19200/54000\tLoss: 71.687\n",
      "22400/54000\tLoss: 72.130\n",
      "25600/54000\tLoss: 71.289\n",
      "28800/54000\tLoss: 71.542\n",
      "32000/54000\tLoss: 71.562\n",
      "35200/54000\tLoss: 71.621\n",
      "38400/54000\tLoss: 71.336\n",
      "41600/54000\tLoss: 71.500\n",
      "44800/54000\tLoss: 71.632\n",
      "48000/54000\tLoss: 71.777\n",
      "51200/54000\tLoss: 71.062\n",
      "Valid Loss: 72.106, Recon Error: 0.014\n",
      "72.10552629511407\n",
      "Epoch: 72 Average loss: 71.59 Valid loss: 72.10552629511407\tRecon Error:0.014\n",
      "0/54000\tLoss: 68.954\n",
      "3200/54000\tLoss: 71.921\n",
      "6400/54000\tLoss: 71.613\n",
      "9600/54000\tLoss: 71.585\n",
      "12800/54000\tLoss: 71.812\n",
      "16000/54000\tLoss: 71.417\n",
      "19200/54000\tLoss: 71.224\n",
      "22400/54000\tLoss: 72.044\n",
      "25600/54000\tLoss: 71.451\n",
      "28800/54000\tLoss: 71.417\n",
      "32000/54000\tLoss: 71.292\n",
      "35200/54000\tLoss: 72.007\n",
      "38400/54000\tLoss: 71.341\n",
      "41600/54000\tLoss: 71.503\n",
      "44800/54000\tLoss: 71.181\n",
      "48000/54000\tLoss: 71.211\n",
      "51200/54000\tLoss: 72.039\n",
      "Valid Loss: 72.186, Recon Error: 0.014\n",
      "72.18556075400494\n",
      "Epoch: 73 Average loss: 71.58 Valid loss: 72.18556075400494\tRecon Error:0.014\n",
      "0/54000\tLoss: 70.212\n",
      "3200/54000\tLoss: 71.504\n",
      "6400/54000\tLoss: 71.737\n",
      "9600/54000\tLoss: 71.298\n",
      "12800/54000\tLoss: 70.613\n",
      "16000/54000\tLoss: 71.887\n",
      "19200/54000\tLoss: 71.177\n",
      "22400/54000\tLoss: 71.663\n",
      "25600/54000\tLoss: 71.070\n",
      "28800/54000\tLoss: 71.229\n",
      "32000/54000\tLoss: 71.861\n",
      "35200/54000\tLoss: 71.404\n",
      "38400/54000\tLoss: 71.290\n",
      "41600/54000\tLoss: 71.051\n",
      "44800/54000\tLoss: 71.664\n",
      "48000/54000\tLoss: 71.185\n",
      "51200/54000\tLoss: 71.551\n",
      "Valid Loss: 71.875, Recon Error: 0.014\n",
      "71.87501956046896\n",
      "Epoch: 74 Average loss: 71.42 Valid loss: 71.87501956046896\tRecon Error:0.014\n",
      "0/54000\tLoss: 68.703\n",
      "3200/54000\tLoss: 71.615\n",
      "6400/54000\tLoss: 71.109\n",
      "9600/54000\tLoss: 71.175\n",
      "12800/54000\tLoss: 71.492\n",
      "16000/54000\tLoss: 71.682\n",
      "19200/54000\tLoss: 71.645\n",
      "22400/54000\tLoss: 71.558\n",
      "25600/54000\tLoss: 71.268\n",
      "28800/54000\tLoss: 71.648\n",
      "32000/54000\tLoss: 71.176\n",
      "35200/54000\tLoss: 71.302\n",
      "38400/54000\tLoss: 70.900\n",
      "41600/54000\tLoss: 71.584\n",
      "44800/54000\tLoss: 71.687\n",
      "48000/54000\tLoss: 71.668\n",
      "51200/54000\tLoss: 71.353\n",
      "Valid Loss: 71.908, Recon Error: 0.016\n",
      "71.9081022384319\n",
      "Epoch: 75 Average loss: 71.44 Valid loss: 71.9081022384319\tRecon Error:0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/54000\tLoss: 68.218\n",
      "3200/54000\tLoss: 71.212\n",
      "6400/54000\tLoss: 70.581\n",
      "9600/54000\tLoss: 71.086\n",
      "12800/54000\tLoss: 71.348\n",
      "16000/54000\tLoss: 71.657\n",
      "19200/54000\tLoss: 71.491\n",
      "22400/54000\tLoss: 71.323\n",
      "25600/54000\tLoss: 71.154\n",
      "28800/54000\tLoss: 71.402\n",
      "32000/54000\tLoss: 71.307\n",
      "35200/54000\tLoss: 71.379\n",
      "38400/54000\tLoss: 70.933\n",
      "41600/54000\tLoss: 70.809\n",
      "44800/54000\tLoss: 71.104\n",
      "48000/54000\tLoss: 71.731\n",
      "51200/54000\tLoss: 71.195\n",
      "Valid Loss: 71.852, Recon Error: 0.014\n",
      "71.8522652159346\n",
      "Epoch: 76 Average loss: 71.26 Valid loss: 71.8522652159346\tRecon Error:0.014\n",
      "0/54000\tLoss: 70.639\n",
      "3200/54000\tLoss: 71.411\n",
      "6400/54000\tLoss: 70.652\n",
      "9600/54000\tLoss: 71.496\n",
      "12800/54000\tLoss: 70.928\n",
      "16000/54000\tLoss: 71.435\n",
      "19200/54000\tLoss: 71.587\n",
      "22400/54000\tLoss: 71.112\n",
      "25600/54000\tLoss: 71.124\n",
      "28800/54000\tLoss: 70.864\n",
      "32000/54000\tLoss: 70.793\n",
      "35200/54000\tLoss: 71.685\n",
      "38400/54000\tLoss: 71.145\n",
      "41600/54000\tLoss: 71.263\n",
      "44800/54000\tLoss: 71.234\n",
      "48000/54000\tLoss: 71.298\n",
      "51200/54000\tLoss: 71.243\n",
      "Valid Loss: 71.613, Recon Error: 0.014\n",
      "71.61311218586374\n",
      "Epoch: 77 Average loss: 71.23 Valid loss: 71.61311218586374\tRecon Error:0.014\n",
      "0/54000\tLoss: 71.052\n",
      "3200/54000\tLoss: 71.134\n",
      "6400/54000\tLoss: 70.945\n",
      "9600/54000\tLoss: 71.584\n",
      "12800/54000\tLoss: 71.363\n",
      "16000/54000\tLoss: 70.900\n",
      "19200/54000\tLoss: 70.994\n",
      "22400/54000\tLoss: 71.388\n",
      "25600/54000\tLoss: 71.354\n",
      "28800/54000\tLoss: 71.054\n",
      "32000/54000\tLoss: 71.489\n",
      "35200/54000\tLoss: 71.210\n",
      "38400/54000\tLoss: 71.269\n",
      "41600/54000\tLoss: 71.047\n",
      "44800/54000\tLoss: 71.419\n",
      "48000/54000\tLoss: 70.737\n",
      "51200/54000\tLoss: 71.322\n",
      "Valid Loss: 71.607, Recon Error: 0.015\n",
      "71.60748859162027\n",
      "Epoch: 78 Average loss: 71.22 Valid loss: 71.60748859162027\tRecon Error:0.015\n",
      "0/54000\tLoss: 71.510\n",
      "3200/54000\tLoss: 71.521\n",
      "6400/54000\tLoss: 71.526\n",
      "9600/54000\tLoss: 71.027\n",
      "12800/54000\tLoss: 71.018\n",
      "16000/54000\tLoss: 71.053\n",
      "19200/54000\tLoss: 71.041\n",
      "22400/54000\tLoss: 71.362\n",
      "25600/54000\tLoss: 71.109\n",
      "28800/54000\tLoss: 71.340\n",
      "32000/54000\tLoss: 71.160\n",
      "35200/54000\tLoss: 70.850\n",
      "38400/54000\tLoss: 70.849\n",
      "41600/54000\tLoss: 71.442\n",
      "44800/54000\tLoss: 71.298\n",
      "48000/54000\tLoss: 71.171\n",
      "51200/54000\tLoss: 71.305\n",
      "Valid Loss: 72.091, Recon Error: 0.016\n",
      "72.09149819232047\n",
      "Epoch: 79 Average loss: 71.22 Valid loss: 72.09149819232047\tRecon Error:0.016\n",
      "0/54000\tLoss: 72.368\n",
      "3200/54000\tLoss: 70.884\n",
      "6400/54000\tLoss: 71.599\n",
      "9600/54000\tLoss: 70.467\n",
      "12800/54000\tLoss: 71.176\n",
      "16000/54000\tLoss: 70.596\n",
      "19200/54000\tLoss: 71.319\n",
      "22400/54000\tLoss: 70.951\n",
      "25600/54000\tLoss: 70.844\n",
      "28800/54000\tLoss: 71.542\n",
      "32000/54000\tLoss: 70.926\n",
      "35200/54000\tLoss: 70.891\n",
      "38400/54000\tLoss: 71.326\n",
      "41600/54000\tLoss: 70.535\n",
      "44800/54000\tLoss: 71.428\n",
      "48000/54000\tLoss: 70.755\n",
      "51200/54000\tLoss: 71.570\n",
      "Valid Loss: 71.412, Recon Error: 0.016\n",
      "71.41201067985372\n",
      "Epoch: 80 Average loss: 71.04 Valid loss: 71.41201067985372\tRecon Error:0.016\n",
      "0/54000\tLoss: 69.348\n",
      "3200/54000\tLoss: 70.739\n",
      "6400/54000\tLoss: 71.182\n",
      "9600/54000\tLoss: 71.489\n",
      "12800/54000\tLoss: 71.663\n",
      "16000/54000\tLoss: 70.839\n",
      "19200/54000\tLoss: 70.875\n",
      "22400/54000\tLoss: 70.814\n",
      "25600/54000\tLoss: 71.141\n",
      "28800/54000\tLoss: 71.510\n",
      "32000/54000\tLoss: 70.966\n",
      "35200/54000\tLoss: 71.241\n",
      "38400/54000\tLoss: 71.021\n",
      "41600/54000\tLoss: 71.012\n",
      "44800/54000\tLoss: 71.447\n",
      "48000/54000\tLoss: 70.968\n",
      "51200/54000\tLoss: 71.373\n",
      "Valid Loss: 71.537, Recon Error: 0.017\n",
      "71.53717779605947\n",
      "Epoch: 81 Average loss: 71.15 Valid loss: 71.53717779605947\tRecon Error:0.017\n",
      "0/54000\tLoss: 68.466\n",
      "3200/54000\tLoss: 71.100\n",
      "6400/54000\tLoss: 70.925\n",
      "9600/54000\tLoss: 70.930\n",
      "12800/54000\tLoss: 71.499\n",
      "16000/54000\tLoss: 70.567\n",
      "19200/54000\tLoss: 70.986\n",
      "22400/54000\tLoss: 70.853\n",
      "25600/54000\tLoss: 71.251\n",
      "28800/54000\tLoss: 71.471\n",
      "32000/54000\tLoss: 70.640\n",
      "35200/54000\tLoss: 71.333\n",
      "38400/54000\tLoss: 71.232\n",
      "41600/54000\tLoss: 71.075\n",
      "44800/54000\tLoss: 71.124\n",
      "48000/54000\tLoss: 71.143\n",
      "51200/54000\tLoss: 71.302\n",
      "Valid Loss: 71.661, Recon Error: 0.016\n",
      "71.66083583425969\n",
      "Epoch: 82 Average loss: 71.08 Valid loss: 71.66083583425969\tRecon Error:0.016\n",
      "0/54000\tLoss: 67.237\n",
      "3200/54000\tLoss: 71.181\n",
      "6400/54000\tLoss: 71.541\n",
      "9600/54000\tLoss: 71.269\n",
      "12800/54000\tLoss: 71.212\n",
      "16000/54000\tLoss: 70.929\n",
      "19200/54000\tLoss: 71.176\n",
      "22400/54000\tLoss: 70.869\n",
      "25600/54000\tLoss: 71.281\n",
      "28800/54000\tLoss: 71.130\n",
      "32000/54000\tLoss: 70.621\n",
      "35200/54000\tLoss: 70.740\n",
      "38400/54000\tLoss: 70.962\n",
      "41600/54000\tLoss: 70.705\n",
      "44800/54000\tLoss: 71.326\n",
      "48000/54000\tLoss: 70.927\n",
      "51200/54000\tLoss: 71.264\n",
      "Valid Loss: 71.432, Recon Error: 0.015\n",
      "71.43221282958984\n",
      "Epoch: 83 Average loss: 71.11 Valid loss: 71.43221282958984\tRecon Error:0.015\n",
      "0/54000\tLoss: 72.348\n",
      "3200/54000\tLoss: 70.969\n",
      "6400/54000\tLoss: 70.938\n",
      "9600/54000\tLoss: 70.480\n",
      "12800/54000\tLoss: 71.360\n",
      "16000/54000\tLoss: 70.546\n",
      "19200/54000\tLoss: 71.101\n",
      "22400/54000\tLoss: 70.862\n",
      "25600/54000\tLoss: 70.654\n",
      "28800/54000\tLoss: 70.536\n",
      "32000/54000\tLoss: 70.850\n",
      "35200/54000\tLoss: 70.581\n",
      "38400/54000\tLoss: 70.668\n",
      "41600/54000\tLoss: 70.939\n",
      "44800/54000\tLoss: 71.072\n",
      "48000/54000\tLoss: 70.731\n",
      "51200/54000\tLoss: 70.762\n",
      "Valid Loss: 71.272, Recon Error: 0.015\n",
      "71.27172689234956\n",
      "Epoch: 84 Average loss: 70.83 Valid loss: 71.27172689234956\tRecon Error:0.015\n",
      "0/54000\tLoss: 69.015\n",
      "3200/54000\tLoss: 70.769\n",
      "6400/54000\tLoss: 70.343\n",
      "9600/54000\tLoss: 70.395\n",
      "12800/54000\tLoss: 70.514\n",
      "16000/54000\tLoss: 70.505\n",
      "19200/54000\tLoss: 70.968\n",
      "22400/54000\tLoss: 70.502\n",
      "25600/54000\tLoss: 70.808\n",
      "28800/54000\tLoss: 70.548\n",
      "32000/54000\tLoss: 70.371\n",
      "35200/54000\tLoss: 70.987\n",
      "38400/54000\tLoss: 70.957\n",
      "41600/54000\tLoss: 71.164\n",
      "44800/54000\tLoss: 71.045\n",
      "48000/54000\tLoss: 70.778\n",
      "51200/54000\tLoss: 70.728\n",
      "Valid Loss: 71.509, Recon Error: 0.015\n",
      "71.50909261500581\n",
      "Epoch: 85 Average loss: 70.74 Valid loss: 71.50909261500581\tRecon Error:0.015\n",
      "0/54000\tLoss: 65.220\n",
      "3200/54000\tLoss: 71.098\n",
      "6400/54000\tLoss: 70.115\n",
      "9600/54000\tLoss: 70.444\n",
      "12800/54000\tLoss: 70.521\n",
      "16000/54000\tLoss: 71.092\n",
      "19200/54000\tLoss: 70.981\n",
      "22400/54000\tLoss: 70.529\n",
      "25600/54000\tLoss: 70.953\n",
      "28800/54000\tLoss: 70.697\n",
      "32000/54000\tLoss: 70.409\n",
      "35200/54000\tLoss: 70.774\n",
      "38400/54000\tLoss: 70.835\n",
      "41600/54000\tLoss: 71.383\n",
      "44800/54000\tLoss: 70.442\n",
      "48000/54000\tLoss: 70.603\n",
      "51200/54000\tLoss: 71.182\n",
      "Valid Loss: 71.474, Recon Error: 0.016\n",
      "71.47372533919963\n",
      "Epoch: 86 Average loss: 70.78 Valid loss: 71.47372533919963\tRecon Error:0.016\n",
      "0/54000\tLoss: 71.164\n",
      "3200/54000\tLoss: 70.828\n",
      "6400/54000\tLoss: 70.310\n",
      "9600/54000\tLoss: 70.520\n",
      "12800/54000\tLoss: 70.248\n",
      "16000/54000\tLoss: 71.071\n",
      "19200/54000\tLoss: 70.861\n",
      "22400/54000\tLoss: 70.717\n",
      "25600/54000\tLoss: 70.708\n",
      "28800/54000\tLoss: 70.276\n",
      "32000/54000\tLoss: 70.595\n",
      "35200/54000\tLoss: 71.086\n",
      "38400/54000\tLoss: 71.076\n",
      "41600/54000\tLoss: 70.313\n",
      "44800/54000\tLoss: 71.009\n",
      "48000/54000\tLoss: 70.358\n",
      "51200/54000\tLoss: 70.439\n",
      "Valid Loss: 71.363, Recon Error: 0.015\n",
      "71.36316210158328\n",
      "Epoch: 87 Average loss: 70.66 Valid loss: 71.36316210158328\tRecon Error:0.015\n",
      "0/54000\tLoss: 70.505\n",
      "3200/54000\tLoss: 70.947\n",
      "6400/54000\tLoss: 70.509\n",
      "9600/54000\tLoss: 70.717\n",
      "12800/54000\tLoss: 70.581\n",
      "16000/54000\tLoss: 70.717\n",
      "19200/54000\tLoss: 70.699\n",
      "22400/54000\tLoss: 71.293\n",
      "25600/54000\tLoss: 70.805\n",
      "28800/54000\tLoss: 71.130\n",
      "32000/54000\tLoss: 70.376\n",
      "35200/54000\tLoss: 70.469\n",
      "38400/54000\tLoss: 71.032\n",
      "41600/54000\tLoss: 70.817\n",
      "44800/54000\tLoss: 70.419\n",
      "48000/54000\tLoss: 70.650\n",
      "51200/54000\tLoss: 71.230\n",
      "Valid Loss: 70.959, Recon Error: 0.016\n",
      "70.95912576229014\n",
      "Epoch: 88 Average loss: 70.78 Valid loss: 70.95912576229014\tRecon Error:0.016\n",
      "0/54000\tLoss: 71.010\n",
      "3200/54000\tLoss: 70.985\n",
      "6400/54000\tLoss: 71.048\n",
      "9600/54000\tLoss: 70.406\n",
      "12800/54000\tLoss: 70.829\n",
      "16000/54000\tLoss: 70.876\n",
      "19200/54000\tLoss: 70.856\n",
      "22400/54000\tLoss: 70.515\n",
      "25600/54000\tLoss: 71.021\n",
      "28800/54000\tLoss: 70.336\n",
      "32000/54000\tLoss: 70.551\n",
      "35200/54000\tLoss: 71.159\n",
      "38400/54000\tLoss: 70.245\n",
      "41600/54000\tLoss: 70.059\n",
      "44800/54000\tLoss: 70.725\n",
      "48000/54000\tLoss: 70.622\n",
      "51200/54000\tLoss: 70.073\n",
      "Valid Loss: 71.226, Recon Error: 0.016\n",
      "71.22611877766062\n",
      "Epoch: 89 Average loss: 70.62 Valid loss: 71.22611877766062\tRecon Error:0.016\n",
      "0/54000\tLoss: 72.863\n",
      "3200/54000\tLoss: 70.458\n",
      "6400/54000\tLoss: 70.413\n",
      "9600/54000\tLoss: 70.507\n",
      "12800/54000\tLoss: 70.625\n",
      "16000/54000\tLoss: 70.364\n",
      "19200/54000\tLoss: 70.807\n",
      "22400/54000\tLoss: 71.013\n",
      "25600/54000\tLoss: 70.578\n",
      "28800/54000\tLoss: 70.624\n",
      "32000/54000\tLoss: 70.070\n",
      "35200/54000\tLoss: 70.140\n",
      "38400/54000\tLoss: 70.818\n",
      "41600/54000\tLoss: 70.740\n",
      "44800/54000\tLoss: 70.927\n",
      "48000/54000\tLoss: 70.484\n",
      "51200/54000\tLoss: 70.261\n",
      "Valid Loss: 71.168, Recon Error: 0.015\n",
      "71.16842838043863\n",
      "Epoch: 90 Average loss: 70.58 Valid loss: 71.16842838043863\tRecon Error:0.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/54000\tLoss: 70.595\n",
      "3200/54000\tLoss: 70.315\n",
      "6400/54000\tLoss: 70.492\n",
      "9600/54000\tLoss: 70.380\n",
      "12800/54000\tLoss: 71.014\n",
      "16000/54000\tLoss: 70.519\n",
      "19200/54000\tLoss: 70.223\n",
      "22400/54000\tLoss: 70.777\n",
      "25600/54000\tLoss: 70.375\n",
      "28800/54000\tLoss: 70.085\n",
      "32000/54000\tLoss: 70.639\n",
      "35200/54000\tLoss: 71.083\n",
      "38400/54000\tLoss: 70.853\n",
      "41600/54000\tLoss: 70.378\n",
      "44800/54000\tLoss: 70.380\n",
      "48000/54000\tLoss: 70.475\n",
      "51200/54000\tLoss: 70.658\n",
      "Valid Loss: 71.161, Recon Error: 0.016\n",
      "71.16067009783805\n",
      "Epoch: 91 Average loss: 70.58 Valid loss: 71.16067009783805\tRecon Error:0.016\n",
      "0/54000\tLoss: 73.045\n",
      "3200/54000\tLoss: 70.378\n",
      "6400/54000\tLoss: 70.349\n",
      "9600/54000\tLoss: 70.564\n",
      "12800/54000\tLoss: 69.958\n",
      "16000/54000\tLoss: 70.186\n",
      "19200/54000\tLoss: 70.447\n",
      "22400/54000\tLoss: 70.404\n",
      "25600/54000\tLoss: 70.427\n",
      "28800/54000\tLoss: 70.738\n",
      "32000/54000\tLoss: 70.409\n",
      "35200/54000\tLoss: 70.877\n",
      "38400/54000\tLoss: 70.348\n",
      "41600/54000\tLoss: 70.729\n",
      "44800/54000\tLoss: 70.018\n",
      "48000/54000\tLoss: 70.193\n",
      "51200/54000\tLoss: 70.965\n",
      "Valid Loss: 70.892, Recon Error: 0.019\n",
      "70.8921067258145\n",
      "Epoch: 92 Average loss: 70.48 Valid loss: 70.8921067258145\tRecon Error:0.019\n",
      "0/54000\tLoss: 68.649\n",
      "3200/54000\tLoss: 70.150\n",
      "6400/54000\tLoss: 70.618\n",
      "9600/54000\tLoss: 70.578\n",
      "12800/54000\tLoss: 70.091\n",
      "16000/54000\tLoss: 70.515\n",
      "19200/54000\tLoss: 70.543\n",
      "22400/54000\tLoss: 70.606\n",
      "25600/54000\tLoss: 70.482\n",
      "28800/54000\tLoss: 70.133\n",
      "32000/54000\tLoss: 70.652\n",
      "35200/54000\tLoss: 71.591\n",
      "38400/54000\tLoss: 70.646\n",
      "41600/54000\tLoss: 70.483\n",
      "44800/54000\tLoss: 70.157\n",
      "48000/54000\tLoss: 70.519\n",
      "51200/54000\tLoss: 71.227\n",
      "Valid Loss: 71.034, Recon Error: 0.016\n",
      "71.03437504869827\n",
      "Epoch: 93 Average loss: 70.57 Valid loss: 71.03437504869827\tRecon Error:0.016\n",
      "0/54000\tLoss: 71.680\n",
      "3200/54000\tLoss: 70.303\n",
      "6400/54000\tLoss: 70.223\n",
      "9600/54000\tLoss: 69.213\n",
      "12800/54000\tLoss: 70.365\n",
      "16000/54000\tLoss: 70.605\n",
      "19200/54000\tLoss: 70.392\n",
      "22400/54000\tLoss: 70.142\n",
      "25600/54000\tLoss: 70.809\n",
      "28800/54000\tLoss: 70.744\n",
      "32000/54000\tLoss: 70.066\n",
      "35200/54000\tLoss: 70.245\n",
      "38400/54000\tLoss: 70.542\n",
      "41600/54000\tLoss: 70.370\n",
      "44800/54000\tLoss: 70.584\n",
      "48000/54000\tLoss: 70.406\n",
      "51200/54000\tLoss: 71.043\n",
      "Valid Loss: 70.721, Recon Error: 0.014\n",
      "70.72070458594789\n",
      "Epoch: 94 Average loss: 70.43 Valid loss: 70.72070458594789\tRecon Error:0.014\n"
     ]
    }
   ],
   "source": [
    "# Train model for 10 epochs\n",
    "# Note this should really be a 100 epochs and trained on a GPU, but this is just to demo\n",
    "###1e-5 6859 1e-4 6727 5e-4 6722 try tanh/L1 loss/beta--->DIP\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "trainer.train(train_loader,valid_loader, epochs=100, save_training_gif=('./training.gif', viz))\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "torch.save(model.state_dict(), 'modelDIP_params.pkl')\n",
    "torch.save(model, './modelDIP')\n",
    "##15.078 - 0.0147  17.209 - 0.0168 error tanh \n",
    "##LR 1e-3 0.019-0.023 worse should pick 5e-4\n",
    "##PLOT THE CURVE!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(latent_spec=latent_spec, img_size=(1, 32, 32)).cuda()\n",
    "model.load_state_dict(torch.load('modelDIP_params.pkl'))\n",
    "#path=\"figures/face/cont_{}/pruned_Beta_ {}lamba{}_ONLYPAIR\".format(n_cont,gamma,0.1)\n",
    "loss = trainer.get_losses()\n",
    "print(len(loss[\"DIP_loss\"]))\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.cuda.is_available()\n",
    "# device = torch.device('cuda')\n",
    "# print(device)\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Chi-square test\n",
    "import torch\n",
    "tensor_one = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor_two = torch.tensor([[6,8,9],[10,11,12]])\n",
    "tensor_list = [tensor_one, tensor_two]\n",
    "tens_list = []\n",
    "for tensor in tensor_list:\n",
    "    \n",
    "    print(tensor)\n",
    "    length = tensor.shape[1]\n",
    "    tens_list.append(torch.mean(tensor.float(),dim=0))\n",
    "    \n",
    "tens_list = torch.stack(tens_list).reshape(1,-1)\n",
    "tens_listT = tens_list.t()\n",
    "matrix = tens_listT.matmul(tens_list)\n",
    "print(matrix)\n",
    "print(\"--------\")\n",
    "Chi2 =0\n",
    "for i in range(len(tensor_list)):\n",
    "    for j in range(len(tensor_list)):\n",
    "        if i > j:\n",
    "            submatrix = matrix[j*length:(j+1)*length,i*length:(i+1)*length]\n",
    "            c_sum = torch.sum(submatrix,dim=0).reshape(-1,1)\n",
    "            \n",
    "            r_sum = torch.sum(submatrix,dim=1).reshape(1,-1)\n",
    "            all_sum = torch.sum(submatrix)\n",
    "            Expectation = c_sum.matmul(r_sum)/all_sum\n",
    "            print(all_sum,c_sum,r_sum,Expectation)\n",
    "            Chi2 += torch.sum((submatrix-Expectation)**2/Expectation)\n",
    "            \n",
    "        \n",
    "print(Chi2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot reconstructions\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 10)) \n",
    "# Get a batch of data\n",
    "for batch, labels in test_loader:\n",
    "    break\n",
    "    \n",
    "#get best model,easrly stopping\n",
    "\n",
    "viz = Visualizer(model)\n",
    "\n",
    "# Reconstruct data using Joint-VAE model\n",
    "recon = viz.reconstructions(batch)\n",
    "\n",
    "# face\n",
    "# recon=np.rollaxis(recon.numpy(), 0, 3)  \n",
    "# print(recon[265:,:,:].max())\n",
    "# recon[:,:,:]=(recon[:,:,:]+1)/2\n",
    "# plt.imshow(recon[:,:,:].astype(float))\n",
    "\n",
    "#MNIST\n",
    "plt.imshow(recon.numpy()[0, :, :].astype(float), cmap='gray')\n",
    "#plt.savefig(path+\"/recon.png\")\n",
    "print(recon.numpy()[0, :, :].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TCR():\n",
    "    totalc = 0\n",
    "    for batch, labels in test_loader:\n",
    "        latent_dist, mask, reg = model.encode(torch.tensor(test_batch[0]).cuda())\n",
    "        mean, var = latent_dist['cont'][0]\n",
    "        cov = covmatrix(mean)\n",
    "        cov[torch.abs(cov)<=1e-6]=0\n",
    "        cor = cov2cor(cov)\n",
    "        totalc += np.sum(cor) \n",
    "\n",
    "    return totalc/len(test_loader)\n",
    "\n",
    "def TCV():\n",
    "    totalc = 0\n",
    "    for batch, labels in test_loader:\n",
    "        latent_dist,mask, reg = model.encode(torch.tensor(test_batch[0]).cuda())\n",
    "        mean, var = latent_dist['cont'][0]\n",
    "        cov = covmatrix(mean).cpu().detach().numpy()\n",
    "        cov = cov-np.diag(np.diag(cov))\n",
    "        totalc += np.sum(cov**2) \n",
    "        \n",
    "    return totalc/len(test_loader)\n",
    "\n",
    "\n",
    "def covmatrix(mean):\n",
    "    exp_mu = torch.mean(mean, dim=0)  #####mean through batch\n",
    "\n",
    "    # expectation of mu mu.tranpose\n",
    "    mu_expand1 = mean.unsqueeze(1)  #####(batch_size, 1, number of mean of latent variables)\n",
    "    mu_expand2 = mean.unsqueeze(2)  #####(batch_size, number of mean of latent variables, 1) ignore batch_size, only transpose the means\n",
    "    exp_mu_mu_t = torch.mean(mu_expand1 * mu_expand2, dim=0)\n",
    "\n",
    "    # covariance of model mean\n",
    "    cov = exp_mu_mu_t - exp_mu.unsqueeze(0) * exp_mu.unsqueeze(1) \n",
    "    return cov\n",
    "def cov2cor(c):\n",
    "    #input batch * n_cont\n",
    "    c = c.cpu().detach()\n",
    "    d=np.zeros_like(c)\n",
    "    for i in range(c.shape[0]):\n",
    "        for j in range(c.shape[1]):\n",
    "            d[i,j]=c[i,j]/(np.sqrt(c[i,i]*c[j,j]+1e-10))\n",
    "    return d\n",
    "tcor=TCR()\n",
    "tcov=TCV()\n",
    "print(tcor,tcov)\n",
    "trainer.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###latent space T-SNE visualization\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "samples = torch.zeros(1)\n",
    "labels = torch.zeros(1)\n",
    "for i in range(10):\n",
    "    test_batch = iter(test_loader)\n",
    "    test_batch = next(test_batch)\n",
    "    new_labels =torch.tensor(test_batch[1])\n",
    "    latent_dist= model.encode(torch.tensor(test_batch[0]).cuda())\n",
    "    new_samples = model.reparameterize(latent_dist)\n",
    "    if torch.sum(samples) == 0:\n",
    "        samples =new_samples\n",
    "        labels = new_labels\n",
    "    else:\n",
    "        samples = torch.cat((samples,new_samples),0)\n",
    "        labels = torch.cat((labels, new_labels),0)\n",
    "    #print(samples.shape)\n",
    "    \n",
    "##latent_varibales should be N,D--->N,2\n",
    "\n",
    "\n",
    "# latent_variables = samples.reshape(samples[0],-1)\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "tsne.fit_transform(samples.detach().cpu().numpy())\n",
    "\n",
    "plt.scatter(tsne.embedding_[:,0],tsne.embedding_[:,1])\n",
    "#plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 10 # Number of labels\n",
    "\n",
    "# setup the plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "# define the data\n",
    "x = tsne.embedding_[:,0]\n",
    "y = tsne.embedding_[:,1]\n",
    "tag = labels# Tag each point with a corresponding label    \n",
    "\n",
    "# define the colormap\n",
    "cmap = plt.cm.jet\n",
    "# extract all colors from the .jet map\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "# create the new map\n",
    "cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "# define the bins and normalize\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# make the scatter\n",
    "scat = ax.scatter(x,y,c=tag,s=np.random.randint(100,110,N),cmap=cmap,     norm=norm)\n",
    "# create the colorbar\n",
    "cb = plt.colorbar(scat, spacing='proportional',ticks=bounds)\n",
    "cb.set_label('Custom cbar')\n",
    "ax.set_title('Discrete color mappings')\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "plt.savefig(path+\"/scatter.png\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "t-SNE demo\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X = np.arange(40).reshape(5,4,2)\n",
    "\n",
    "X_new = X.reshape(5,-1)\n",
    "#X = np.array([[[0,0], [0,0], [0,0]], [[0,0], [0,1], [1,1]], [[1,1], [1,0], [0,1]], [[1,1], [1,1], [1,1]]])\n",
    "print(X.shape,X)\n",
    "print(\"--------\")\n",
    "print(X_new)\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit_transform(X)\n",
    "print(tsne.embedding_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot samples\n",
    "\n",
    "samples = viz.samples()\n",
    "plt.imshow(samples.numpy()[0, :174, :], cmap='gray')\n",
    "print(np.sum(samples.numpy()[0, :174, :]))\n",
    "print(samples.numpy()[0, :, :].shape)\n",
    "####origin\n",
    "4*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "import matplotlib as mpl\n",
    "\n",
    "#MNIST\n",
    "samples = viz.samples()\n",
    "sample=samples.numpy()[0, :, :]/2+0.5\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.imsave(path+\"/samples\",samples.numpy()[0, :, :]/2+0.5, cmap='gray')\n",
    "\n",
    "print((sample).min())\n",
    "\n",
    "# face\n",
    "# fig = plt.figure(figsize=(50, 50)) \n",
    "# samples = viz.samples()\n",
    "# samples = np.rollaxis(samples.numpy(), 0, 3)  \n",
    "# print(samples[:,:,0].max())\n",
    "# samples=(samples+1)/2\n",
    "# plt.imshow(samples.astype(float),norm = norm)\n",
    "# plt.imsave(path+\"/samples\",samples)\n",
    "###DIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot all traversals\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "traversals = viz.all_latent_traversals(size=10)\n",
    "\n",
    "#MNIST\n",
    "plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "plt.imsave(path+\"/all_traversals\",traversals.numpy()[0, :, :], cmap='gray')\n",
    "\n",
    "#face\n",
    "# traversals = np.rollaxis(traversals.numpy(), 0, 3)  \n",
    "# traversals=(traversals+1)/2\n",
    "# plt.imshow(traversals)\n",
    "# plt.imsave(path+\"/all_traversals\",traversals)\n",
    "###dip[0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
    "#         0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of some traversals\n",
    "traversals = viz.latent_traversal_grid(cont_idx=5, cont_axis=1, disc_idx=0, disc_axis=0, size=(10, 10))\n",
    "#MNIST\n",
    "plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "plt.imsave(path+\"/contVSdisc\",traversals.numpy()[0, :, :], cmap='gray')\n",
    "\n",
    "traversals.numpy()[0, :, :].max()\n",
    "#face\n",
    "# traversals = np.rollaxis(traversals.numpy(), 0, 3)\n",
    "# traversals=(traversals+1)/2\n",
    "# plt.imshow(traversals)\n",
    "# plt.imsave(path+\"/contVSdisc\",traversals)\n",
    "##origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_t = viz.all_latent_traversals()\n",
    "print(all_t.shape)\n",
    "plt.imshow(all_t.numpy()[0, :, :], cmap='gray')\n",
    "plt.imsave(\"figures/beta/all_\",traversals.numpy()[0, :, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "# Plot a grid of some traversals\n",
    "\n",
    "fig = plt.figure(figsize=(70, 70))  # width, height in inches\n",
    "print(\"continuous\")\n",
    "for i in range(n_cont):\n",
    "    traversals = viz.latent_traversal_line(cont_idx=i, disc_idx=None,size=12)\n",
    "    \n",
    "    #MNIST\n",
    "    sub = fig.add_subplot(n_cont, 1, i + 1)\n",
    "    plt.savefig(path+\"/cont{}.png\".format(i))\n",
    "    plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "    \n",
    "    #FACE\n",
    "#     traversals = np.rollaxis(traversals.numpy(), 0, 3)\n",
    "#     sub = fig.add_subplot(n_cont, 1, i + 1)\n",
    "#     traversals=(traversals+1)/2\n",
    "#     plt.imshow(traversals)   \n",
    "plt.savefig(path+\"/cont.png\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"discrete\")\n",
    "for i in range(n_disc):\n",
    "    traversals = viz.latent_traversal_line(cont_idx=None, disc_idx=i,size=10)\n",
    "    ##MNIST\n",
    "    sub = fig.add_subplot(n_disc, 1, i + 1)\n",
    "    plt.savefig(path+\"/disc{}.png\".format(i))\n",
    "    plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "\n",
    "    #FACE\n",
    "#     traversals = np.rollaxis(traversals.numpy(), 0, 3)\n",
    "#     sub = fig.add_subplot(n_disc, 1, i + 1)\n",
    "# traversals=(traversals+1)/2\n",
    "# plt.savefig(path+\"/disc{}.png\".format(i))\n",
    "# plt.imshow(traversals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from latent_traversals import LatentTraverser\n",
    "from scipy import stats\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import numpy as np\n",
    "import torch\n",
    "from latent_traversals import LatentTraverser\n",
    "from scipy import stats\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "    \n",
    "# face    \n",
    "# def single_traversal(model,n_cont,cont_idx,cont_v,disc,disc_idx,prior):\n",
    "\n",
    "#         # Generate latent traversal\n",
    "# #         latent_samples = latent_traverser.traverse_line(cont_idx=cont_idx,\n",
    "# #                                                              disc_idx=disc_idx,\n",
    "# #                                                              size=size)\n",
    "#         dim = n_cont + sum(disc)\n",
    "#         if prior:\n",
    "#             latent_samples = torch.tensor(np.random.normal(size=(1, dim)))\n",
    "#         else:\n",
    "#             latent_samples= torch.zeros((1,dim))\n",
    "            \n",
    "#         latent_samples[:,disc_idx+n_cont-1] = 1.0\n",
    "#         latent_samples[:,cont_idx]=cont_v\n",
    "        \n",
    "\n",
    "#         # Map samples through decoder\n",
    "#         generated = decode_latents(model, latent_samples.float()).squeeze()\n",
    "#         generated  = np.rollaxis(generated.detach().numpy(), 0, 3)\n",
    "#         generated = (generated +1)/2\n",
    "#         print(generated.min(),generated.max())\n",
    "#         plt.imshow(generated)\n",
    "\n",
    "        \n",
    "# def decode_latents(model, latent_samples):\n",
    "\n",
    "#         latent_samples = Variable(latent_samples)\n",
    "#         if model.use_cuda:\n",
    "#             latent_samples = latent_samples.cuda()\n",
    "#             result = model.decode(latent_samples).cpu()\n",
    "#         return result\n",
    "\n",
    "#MNIST\n",
    "def single_traversal(model,n_cont,cont_idx,cont_v,disc,disc_idx,prior):\n",
    "\n",
    "        # Generate latent traversal\n",
    "#         latent_samples = latent_traverser.traverse_line(cont_idx=cont_idx,\n",
    "#                                                              disc_idx=disc_idx,\n",
    "#                                                              size=size)\n",
    "        dim = n_cont + sum(disc)\n",
    "        if prior:\n",
    "            latent_samples = torch.tensor(np.random.normal(size=(1, dim)))\n",
    "        else:\n",
    "            latent_samples= torch.zeros((1,dim))\n",
    "            \n",
    "        latent_samples[:,disc_idx+n_cont-1] = 1.0\n",
    "        latent_samples[:,cont_idx]=cont_v\n",
    "        \n",
    "\n",
    "        # Map samples through decoder\n",
    "        generated = decode_latents(model, latent_samples.float()).squeeze()\n",
    "        plt.imshow(generated.detach().numpy(),cmap=\"gray\")\n",
    "\n",
    "        \n",
    "def decode_latents(model, latent_samples):\n",
    "\n",
    "        latent_samples = Variable(latent_samples)\n",
    "        if model.use_cuda:\n",
    "            latent_samples = latent_samples.cuda()\n",
    "        return model.decode(latent_samples).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import display\n",
    "def interactive_view(model,n_cont,disc):\n",
    "    \n",
    "    \n",
    "    interact(single_traversal,model=fixed(model),\n",
    "             n_cont=fixed(n_cont), cont_idx=(0,n_cont,1), cont_v=(-2.5,2.5,0.5),\n",
    "             disc=fixed(disc),disc_idx=(0,9,1),\n",
    "             prior=True);\n",
    "             \n",
    "interactive_view(model,n_cont,disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
