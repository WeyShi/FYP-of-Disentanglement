{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a JointVAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST data\n",
    "Build a simple JointVAE model on MNIST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from utils.dataloaders import get_mnist_dataloaders, get_celeba_dataloader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "IMAGE_PATH = 'img_align_celeba/'\n",
    "image_size = 64\n",
    "# SAMPLE_PATH = '../'\n",
    "\n",
    "# if not os.path.exists(SAMPLE_PATH):\n",
    "#     os.makedirs(SAMPLE_PATH)\n",
    "    \n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    #transforms.Scale(image_size),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop((image_size,image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "data_loader = ImageFolder(IMAGE_PATH, transform)\n",
    "\n",
    "\n",
    "#data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "valid_loader, train_loader, test_loader = get_celeba_dataloader(data_loader, \n",
    "                                                                batch_size=128)\n",
    "test_batch = iter(test_loader)\n",
    "test_batch = next(test_batch)\n",
    "new_labels =torch.tensor(test_batch[1])\n",
    "print(torch.tensor(test_batch[0]).shape)\n",
    "#latent_dist = model.encode(torch.tensor(test_batch[0]).cuda())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "limit_a, limit_b, epsilon = -.5, 1.5, 1e-6\n",
    "eps = np.linspace(0.1,0.9,20)\n",
    "def sigmoid(x):\n",
    "    y = 1./(1.+np.exp(-x))\n",
    "    return y\n",
    "def quantile_concrete(x,temperature,qz_loga):\n",
    "        \n",
    "        \"\"\"Implements the quantile, aka inverse CDF, of the 'stretched' concrete distribution\"\"\"\n",
    "        y = sigmoid((np.log(x) - np.log(1 - x) + qz_loga) / temperature)\n",
    "        return y * (limit_b - limit_a) + limit_a\n",
    "\n",
    "z = quantile_concrete(eps,1/20,2)\n",
    "z[z>=1]=1\n",
    "z[z<=0]=0\n",
    "print(z)\n",
    "plt.plot(eps,z)\n",
    "droprate_init = 0.2\n",
    "x = torch.autograd.Variable(torch.Tensor([1, 2, 3, 4]), requires_grad=True)\n",
    "y = torch.autograd.Variable(torch.zeros(4), requires_grad=False).data.normal_(math.log(1 - droprate_init) - math.log(droprate_init), 1e-2)\n",
    "z=(x+y).detach()\n",
    "print(y)\n",
    "#z.is_leaf \n",
    "a=torch.ones((64,32))\n",
    "b=torch.ones((1,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define latent distribution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "L0Pair(256 -> 2*32, droprate_init=0.2, lamba=0.1, temperature=0.05, weight_decay=0.001, local_rep=False)\n",
      "VAE(\n",
      "  (img_to_features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (features_to_hidden): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc_latent): Sequential(\n",
      "    (0): L0Pair(256 -> 2*32, droprate_init=0.2, lamba=0.1, temperature=0.05, weight_decay=0.001, local_rep=False)\n",
      "  )\n",
      "  (fc_alphas): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=42, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (features_to_img): Sequential(\n",
      "    (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloaders import get_mnist_dataloaders, get_celeba_dataloader \n",
    "from torchvision import transforms \n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader \n",
    "import os \n",
    "import torch\n",
    "from jointvae.models import VAE\n",
    "from jointvae.training import Trainer\n",
    "from torch import optim\n",
    "from viz.visualize_c import Visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "valid_loader, train_loader, test_loader = get_mnist_dataloaders(batch_size=64)\n",
    "\n",
    "# Latent distribution will be joint distribution of 10 gaussian normal distributions  7-14\n",
    "# and one 10 dimensional Gumbel Softmax distribution\n",
    "n_cont = 32\n",
    "disc = [10]\n",
    "n_disc = len(disc)\n",
    "latent_spec = {'cont': n_cont,\n",
    "               'disc': disc}\n",
    "\n",
    "device = torch.device('cuda')\n",
    "#model = VAE(latent_spec=latent_spec, img_size=(3, 64, 64)).cuda()\n",
    "model = VAE(latent_spec=latent_spec, img_size=(1, 32, 32)).cuda()\n",
    "print(model)\n",
    "\n",
    "\n",
    "lr=5e-4\n",
    "# Build optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# Define the capacities\n",
    "# Continuous channels\n",
    "gamma=1.0\n",
    "cont_capacity = [0.0, 0.0, 25000, gamma]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "# Discrete channels\n",
    "disc_capacity = [0.0, 0.0, 25000, gamma]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "\n",
    "\n",
    "lambda_d = 2\n",
    "lambda_od = 10*lambda_d\n",
    "lambda_dis = 30*lambda_d \n",
    "path=\"figures/face/cont_{}/Beta_ {}lambda{}\".format(n_cont,gamma,lambda_d)\n",
    "# Build a trainer\n",
    "trainer = Trainer(model, optimizer,\n",
    "                  cont_capacity=cont_capacity,\n",
    "                  disc_capacity=disc_capacity,lambda_d = lambda_d,\n",
    "                  lambda_od = lambda_od, lambda_dis = lambda_dis )\n",
    "# Build a visualizer which will be passed to trainer to visualize progress during training\n",
    "viz = Visualizer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from jointvae.training import Trainer\n",
    "\n",
    "\n",
    "trainer._train_epoch(train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/mli/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/54000\tLoss: 359.006\tL0 Loss: 0.424\n",
      "3200/54000\tLoss: 214.413\tL0 Loss: 0.424\n",
      "6400/54000\tLoss: 141.409\tL0 Loss: 0.424\n",
      "9600/54000\tLoss: 139.392\tL0 Loss: 0.424\n",
      "12800/54000\tLoss: 137.742\tL0 Loss: 0.424\n",
      "16000/54000\tLoss: 135.758\tL0 Loss: 0.424\n",
      "19200/54000\tLoss: 135.845\tL0 Loss: 0.424\n",
      "22400/54000\tLoss: 132.634\tL0 Loss: 0.424\n",
      "25600/54000\tLoss: 127.722\tL0 Loss: 0.424\n",
      "28800/54000\tLoss: 125.477\tL0 Loss: 0.425\n",
      "32000/54000\tLoss: 123.010\tL0 Loss: 0.425\n",
      "35200/54000\tLoss: 119.286\tL0 Loss: 0.425\n",
      "38400/54000\tLoss: 114.004\tL0 Loss: 0.425\n",
      "41600/54000\tLoss: 111.437\tL0 Loss: 0.425\n",
      "44800/54000\tLoss: 111.299\tL0 Loss: 0.425\n",
      "48000/54000\tLoss: 109.571\tL0 Loss: 0.426\n",
      "51200/54000\tLoss: 108.628\tL0 Loss: 0.426\n",
      "Valid Loss: 107.173, L0 Loss: 0.000\n",
      "107.17344779156625\n",
      "Epoch: 1 Average loss: 129.69 Valid loss: 107.17344779156625\tRecon:47.466\n",
      "0/54000\tLoss: 104.489\tL0 Loss: 0.426\n",
      "3200/54000\tLoss: 107.499\tL0 Loss: 0.426\n",
      "6400/54000\tLoss: 106.887\tL0 Loss: 0.426\n",
      "9600/54000\tLoss: 106.099\tL0 Loss: 0.426\n",
      "12800/54000\tLoss: 105.821\tL0 Loss: 0.427\n",
      "16000/54000\tLoss: 108.665\tL0 Loss: 0.427\n",
      "19200/54000\tLoss: 109.590\tL0 Loss: 0.427\n",
      "22400/54000\tLoss: 105.463\tL0 Loss: 0.427\n",
      "25600/54000\tLoss: 103.229\tL0 Loss: 0.427\n",
      "28800/54000\tLoss: 101.786\tL0 Loss: 0.428\n",
      "32000/54000\tLoss: 102.595\tL0 Loss: 0.428\n",
      "35200/54000\tLoss: 101.313\tL0 Loss: 0.428\n",
      "38400/54000\tLoss: 102.501\tL0 Loss: 0.428\n",
      "41600/54000\tLoss: 101.086\tL0 Loss: 0.428\n",
      "44800/54000\tLoss: 102.300\tL0 Loss: 0.429\n",
      "48000/54000\tLoss: 100.811\tL0 Loss: 0.429\n",
      "51200/54000\tLoss: 101.693\tL0 Loss: 0.429\n",
      "Valid Loss: 99.332, L0 Loss: 0.000\n",
      "99.3322173585283\n",
      "Epoch: 2 Average loss: 104.07 Valid loss: 99.3322173585283\tRecon:31.558\n",
      "0/54000\tLoss: 100.251\tL0 Loss: 0.429\n",
      "3200/54000\tLoss: 99.405\tL0 Loss: 0.429\n",
      "6400/54000\tLoss: 98.739\tL0 Loss: 0.429\n",
      "9600/54000\tLoss: 99.808\tL0 Loss: 0.430\n",
      "12800/54000\tLoss: 100.317\tL0 Loss: 0.430\n",
      "16000/54000\tLoss: 99.040\tL0 Loss: 0.430\n",
      "19200/54000\tLoss: 99.752\tL0 Loss: 0.430\n",
      "22400/54000\tLoss: 100.958\tL0 Loss: 0.430\n",
      "25600/54000\tLoss: 101.424\tL0 Loss: 0.430\n",
      "28800/54000\tLoss: 99.189\tL0 Loss: 0.431\n",
      "32000/54000\tLoss: 98.738\tL0 Loss: 0.431\n",
      "35200/54000\tLoss: 98.902\tL0 Loss: 0.431\n",
      "38400/54000\tLoss: 97.986\tL0 Loss: 0.431\n",
      "41600/54000\tLoss: 97.128\tL0 Loss: 0.431\n",
      "44800/54000\tLoss: 97.392\tL0 Loss: 0.431\n",
      "48000/54000\tLoss: 95.792\tL0 Loss: 0.432\n",
      "51200/54000\tLoss: 96.968\tL0 Loss: 0.432\n",
      "Valid Loss: 96.283, L0 Loss: 0.000\n",
      "96.28298942078935\n",
      "Epoch: 3 Average loss: 98.75 Valid loss: 96.28298942078935\tRecon:30.658\n",
      "0/54000\tLoss: 93.845\tL0 Loss: 0.432\n",
      "3200/54000\tLoss: 97.118\tL0 Loss: 0.432\n",
      "6400/54000\tLoss: 97.095\tL0 Loss: 0.432\n",
      "9600/54000\tLoss: 95.355\tL0 Loss: 0.433\n",
      "12800/54000\tLoss: 96.636\tL0 Loss: 0.433\n",
      "16000/54000\tLoss: 96.410\tL0 Loss: 0.433\n",
      "19200/54000\tLoss: 94.708\tL0 Loss: 0.433\n",
      "22400/54000\tLoss: 96.156\tL0 Loss: 0.433\n",
      "25600/54000\tLoss: 97.103\tL0 Loss: 0.433\n"
     ]
    }
   ],
   "source": [
    "# Train model for 10 epochs\n",
    "# Note this should really be a 100 epochs and trained on a GPU, but this is just to demo\n",
    "###1e-5 6859 1e-4 6727 5e-4 6722 try tanh/L1 loss/beta--->DIP\n",
    "trainer.train(train_loader,valid_loader, epochs=100, save_training_gif=('./training.gif', viz))\n",
    "torch.save(model.state_dict(), 'model2_params.pkl')\n",
    "torch.save(model, './model2')\n",
    "##15.078 -   17.209= 0.0147 - 0.0168 error tanh \n",
    "##PLOT THE CURVE!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(latent_spec=latent_spec, img_size=(1, 32, 32)).cuda()\n",
    "model.load_state_dict(torch.load('model2_params.pkl'))\n",
    "path=\"figures/face/cont_{}/pruned_Beta_ {}lamba{}_ONLYPAIR\".format(n_cont,gamma,0.1)\n",
    "loss = trainer.get_losses()\n",
    "print(loss[\"DIP_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.cuda.is_available()\n",
    "# device = torch.device('cuda')\n",
    "# print(device)\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Chi-square test\n",
    "import torch\n",
    "tensor_one = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor_two = torch.tensor([[6,8,9],[10,11,12]])\n",
    "tensor_list = [tensor_one, tensor_two]\n",
    "tens_list = []\n",
    "for tensor in tensor_list:\n",
    "    \n",
    "    print(tensor)\n",
    "    length = tensor.shape[1]\n",
    "    tens_list.append(torch.mean(tensor.float(),dim=0))\n",
    "    \n",
    "tens_list = torch.stack(tens_list).reshape(1,-1)\n",
    "tens_listT = tens_list.t()\n",
    "matrix = tens_listT.matmul(tens_list)\n",
    "print(matrix)\n",
    "print(\"--------\")\n",
    "Chi2 =0\n",
    "for i in range(len(tensor_list)):\n",
    "    for j in range(len(tensor_list)):\n",
    "        if i > j:\n",
    "            submatrix = matrix[j*length:(j+1)*length,i*length:(i+1)*length]\n",
    "            c_sum = torch.sum(submatrix,dim=0).reshape(-1,1)\n",
    "            \n",
    "            r_sum = torch.sum(submatrix,dim=1).reshape(1,-1)\n",
    "            all_sum = torch.sum(submatrix)\n",
    "            Expectation = c_sum.matmul(r_sum)/all_sum\n",
    "            print(all_sum,c_sum,r_sum,Expectation)\n",
    "            Chi2 += torch.sum((submatrix-Expectation)**2/Expectation)\n",
    "            \n",
    "        \n",
    "print(Chi2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot reconstructions\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(50, 50)) \n",
    "# Get a batch of data\n",
    "for batch, labels in test_loader:\n",
    "    break\n",
    "    \n",
    "#get best model,easrly stopping\n",
    "\n",
    "viz = Visualizer(model)\n",
    "\n",
    "# Reconstruct data using Joint-VAE model\n",
    "recon = viz.reconstructions(batch)\n",
    "\n",
    "# face\n",
    "# recon=np.rollaxis(recon.numpy(), 0, 3)  \n",
    "# print(recon[265:,:,:].max())\n",
    "# recon[:,:,:]=(recon[:,:,:]+1)/2\n",
    "# plt.imshow(recon[:,:,:].astype(float))\n",
    "\n",
    "#MNIST\n",
    "plt.imshow(recon.numpy()[0, :, :].astype(float), cmap='gray')\n",
    "#plt.savefig(path+\"/recon.png\")\n",
    "print(recon.numpy()[0, :, :].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_batch = iter(test_loader)\n",
    "test_batch = next(test_batch)\n",
    "latent_dist,mask,_ = model.encode(torch.tensor(test_batch[0]).cuda())\n",
    "\n",
    "print(mask)\n",
    "\n",
    "# for latent in latent_dist['cont'][0]:\n",
    "#     count=torch.zeros((1,32))\n",
    "#     latent[latent<1e-7]=0\n",
    "    \n",
    "#     for i in range(128):\n",
    "    \n",
    "#     #print(latent[i].size(),torch.nonzero(latent[i]))#len(torch.nonzero(latent[0]==0))\n",
    "#         count[latent[i].reshape(1,32)!=0] += 1\n",
    "#     print(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###latent space T-SNE visualization\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "samples = torch.zeros(1)\n",
    "labels = torch.zeros(1)\n",
    "for i in range(10):\n",
    "    test_batch = iter(test_loader)\n",
    "    test_batch = next(test_batch)\n",
    "    new_labels =torch.tensor(test_batch[1])\n",
    "    latent_dist,_ ,_= model.encode(torch.tensor(test_batch[0]).cuda())\n",
    "    new_samples = model.reparameterize(latent_dist)\n",
    "    print(new_samples.shape,i)\n",
    "    if torch.sum(samples) == 0:\n",
    "        samples =new_samples\n",
    "        labels = new_labels\n",
    "    else:\n",
    "        samples = torch.cat((samples,new_samples),0)\n",
    "        labels = torch.cat((labels, new_labels),0)\n",
    "    #print(samples.shape)\n",
    "    \n",
    "##latent_varibales should be N,D--->N,2\n",
    "\n",
    "\n",
    "# latent_variables = samples.reshape(samples[0],-1)\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "tsne.fit_transform(samples.detach().cpu().numpy())\n",
    "\n",
    "plt.scatter(tsne.embedding_[:,0],tsne.embedding_[:,1])\n",
    "#plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 10 # Number of labels\n",
    "\n",
    "# setup the plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "# define the data\n",
    "x = tsne.embedding_[:,0]\n",
    "y = tsne.embedding_[:,1]\n",
    "tag = labels# Tag each point with a corresponding label    \n",
    "\n",
    "# define the colormap\n",
    "cmap = plt.cm.jet\n",
    "# extract all colors from the .jet map\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "# create the new map\n",
    "cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "# define the bins and normalize\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# make the scatter\n",
    "scat = ax.scatter(x,y,c=tag,s=np.random.randint(100,110,N),cmap=cmap,     norm=norm)\n",
    "# create the colorbar\n",
    "cb = plt.colorbar(scat, spacing='proportional',ticks=bounds)\n",
    "cb.set_label('Custom cbar')\n",
    "ax.set_title('Discrete color mappings')\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "plt.savefig(path+\"/scatter.png\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "t-SNE demo\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X = np.arange(40).reshape(5,4,2)\n",
    "\n",
    "X_new = X.reshape(5,-1)\n",
    "#X = np.array([[[0,0], [0,0], [0,0]], [[0,0], [0,1], [1,1]], [[1,1], [1,0], [0,1]], [[1,1], [1,1], [1,1]]])\n",
    "print(X.shape,X)\n",
    "print(\"--------\")\n",
    "print(X_new)\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit_transform(X)\n",
    "print(tsne.embedding_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot samples\n",
    "\n",
    "samples = viz.samples()\n",
    "plt.imshow(samples.numpy()[0, :174, :], cmap='gray')\n",
    "print(np.sum(samples.numpy()[0, :174, :]))\n",
    "print(samples.numpy()[0, :, :].shape)\n",
    "####origin\n",
    "4*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "import matplotlib as mpl\n",
    "\n",
    "#MNIST\n",
    "samples = viz.samples()\n",
    "sample=samples.numpy()[0, :, :]/2+0.5\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.imsave(path+\"/samples\",samples.numpy()[0, :, :]/2+0.5, cmap='gray')\n",
    "\n",
    "print((sample).min())\n",
    "\n",
    "# face\n",
    "# fig = plt.figure(figsize=(50, 50)) \n",
    "# samples = viz.samples()\n",
    "# samples = np.rollaxis(samples.numpy(), 0, 3)  \n",
    "# print(samples[:,:,0].max())\n",
    "# samples=(samples+1)/2\n",
    "# plt.imshow(samples.astype(float),norm = norm)\n",
    "# plt.imsave(path+\"/samples\",samples)\n",
    "###DIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot all traversals\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "traversals = viz.all_latent_traversals(size=10)\n",
    "\n",
    "#MNIST\n",
    "plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "plt.imsave(path+\"/all_traversals\",traversals.numpy()[0, :, :], cmap='gray')\n",
    "\n",
    "#face\n",
    "# traversals = np.rollaxis(traversals.numpy(), 0, 3)  \n",
    "# traversals=(traversals+1)/2\n",
    "# plt.imshow(traversals)\n",
    "# plt.imsave(path+\"/all_traversals\",traversals)\n",
    "###dip[0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
    "#         0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of some traversals\n",
    "traversals = viz.latent_traversal_grid(cont_idx=2, cont_axis=1, disc_idx=0, disc_axis=0, size=(10, 10))\n",
    "#MNIST\n",
    "plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "plt.imsave(path+\"/contVSdisc\",traversals.numpy()[0, :, :], cmap='gray')\n",
    "\n",
    "traversals.numpy()[0, :, :].max()\n",
    "#face\n",
    "# traversals = np.rollaxis(traversals.numpy(), 0, 3)\n",
    "# traversals=(traversals+1)/2\n",
    "# plt.imshow(traversals)\n",
    "# plt.imsave(path+\"/contVSdisc\",traversals)\n",
    "##origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_t = viz.all_latent_traversals()\n",
    "print(all_t.shape)\n",
    "plt.imshow(all_t.numpy()[0, :, :], cmap='gray')\n",
    "plt.imsave(\"figures/beta/all_\",traversals.numpy()[0, :, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "# Plot a grid of some traversals\n",
    "\n",
    "fig = plt.figure(figsize=(70, 70))  # width, height in inches\n",
    "print(\"continuous\")\n",
    "for i in range(n_cont):\n",
    "    traversals = viz.latent_traversal_line(cont_idx=i, disc_idx=None,size=12)\n",
    "    \n",
    "    #MNIST\n",
    "    sub = fig.add_subplot(n_cont, 1, i + 1)\n",
    "    plt.savefig(path+\"/cont{}.png\".format(i))\n",
    "    plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "    print(traversals.numpy()[0, :, :].max(),traversals.numpy()[0, :, :].min())\n",
    "    #FACE\n",
    "#     traversals = np.rollaxis(traversals.numpy(), 0, 3)\n",
    "#     sub = fig.add_subplot(n_cont, 1, i + 1)\n",
    "#     traversals=(traversals+1)/2\n",
    "#     plt.imshow(traversals)   \n",
    "plt.savefig(path+\"/cont.png\")\n",
    "    \n",
    "    \n",
    "  # width, height in inches\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(n_cont):\n",
    "#     traversals = viz.latent_traversal_line(cont_idx=i, disc_idx=None)\n",
    "#     plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "# for i in range(n_disc):\n",
    "#     traversals = viz.latent_traversal_line(cont_idx=None, disc_idx=i)\n",
    "#     plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"discrete\")\n",
    "for i in range(n_disc):\n",
    "    traversals = viz.latent_traversal_line(cont_idx=None, disc_idx=i,size=10)\n",
    "    ##MNIST\n",
    "    sub = fig.add_subplot(n_disc, 1, i + 1)\n",
    "    plt.savefig(path+\"/disc{}.png\".format(i))\n",
    "    plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "\n",
    "    #FACE\n",
    "#     traversals = np.rollaxis(traversals.numpy(), 0, 3)\n",
    "#     sub = fig.add_subplot(n_disc, 1, i + 1)\n",
    "# traversals=(traversals+1)/2\n",
    "# plt.savefig(path+\"/disc{}.png\".format(i))\n",
    "# plt.imshow(traversals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from latent_traversals import LatentTraverser\n",
    "from scipy import stats\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import numpy as np\n",
    "import torch\n",
    "from latent_traversals import LatentTraverser\n",
    "from scipy import stats\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "    \n",
    "# face    \n",
    "# def single_traversal(model,n_cont,cont_idx,cont_v,disc,disc_idx,prior):\n",
    "\n",
    "#         # Generate latent traversal\n",
    "# #         latent_samples = latent_traverser.traverse_line(cont_idx=cont_idx,\n",
    "# #                                                              disc_idx=disc_idx,\n",
    "# #                                                              size=size)\n",
    "#         dim = n_cont + sum(disc)\n",
    "#         if prior:\n",
    "#             latent_samples = torch.tensor(np.random.normal(size=(1, dim)))\n",
    "#         else:\n",
    "#             latent_samples= torch.zeros((1,dim))\n",
    "            \n",
    "#         latent_samples[:,disc_idx+n_cont-1] = 1.0\n",
    "#         latent_samples[:,cont_idx]=cont_v\n",
    "        \n",
    "\n",
    "#         # Map samples through decoder\n",
    "#         generated = decode_latents(model, latent_samples.float()).squeeze()\n",
    "#         generated  = np.rollaxis(generated.detach().numpy(), 0, 3)\n",
    "#         generated = (generated +1)/2\n",
    "#         print(generated.min(),generated.max())\n",
    "#         plt.imshow(generated)\n",
    "\n",
    "        \n",
    "# def decode_latents(model, latent_samples):\n",
    "\n",
    "#         latent_samples = Variable(latent_samples)\n",
    "#         if model.use_cuda:\n",
    "#             latent_samples = latent_samples.cuda()\n",
    "#             result = model.decode(latent_samples).cpu()\n",
    "#         return result\n",
    "\n",
    "#MNIST\n",
    "def single_traversal(model,n_cont,cont_idx,cont_v,disc,disc_idx,prior):\n",
    "\n",
    "        # Generate latent traversal\n",
    "#         latent_samples = latent_traverser.traverse_line(cont_idx=cont_idx,\n",
    "#                                                              disc_idx=disc_idx,\n",
    "#                                                              size=size)\n",
    "        dim = n_cont + sum(disc)\n",
    "        if prior:\n",
    "            latent_samples = torch.tensor(np.random.normal(size=(1, dim)))\n",
    "        else:\n",
    "            latent_samples= torch.zeros((1,dim))\n",
    "            \n",
    "        latent_samples[:,disc_idx+n_cont-1] = 1.0\n",
    "        latent_samples[:,cont_idx]=cont_v\n",
    "        \n",
    "\n",
    "        # Map samples through decoder\n",
    "        generated = decode_latents(model, latent_samples.float()).squeeze()\n",
    "        plt.imshow(generated.detach().numpy(),cmap=\"gray\")\n",
    "\n",
    "        \n",
    "def decode_latents(model, latent_samples):\n",
    "\n",
    "        latent_samples = Variable(latent_samples)\n",
    "        if model.use_cuda:\n",
    "            latent_samples = latent_samples.cuda()\n",
    "        return model.decode(latent_samples).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import display\n",
    "def interactive_view(model,n_cont,disc):\n",
    "    \n",
    "    \n",
    "    interact(single_traversal,model=fixed(model),\n",
    "             n_cont=fixed(n_cont), cont_idx=(0,n_cont,1), cont_v=(-2.5,2.5,0.5),\n",
    "             disc=fixed(disc),disc_idx=(0,9,1),\n",
    "             prior=True);\n",
    "             \n",
    "interactive_view(model,n_cont,disc)\n",
    "###dip[0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
    "#         0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
