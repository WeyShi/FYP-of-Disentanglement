{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a JointVAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST data\n",
    "Build a simple JointVAE model on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162079 20259 20261\n",
      "torch.Size([128, 3, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/mli/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/data/anaconda/envs/mli/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloaders import get_mnist_dataloaders, get_celeba_dataloader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from disentanglement_lib.data.ground_truth import dsprites\n",
    "import os\n",
    "import torch\n",
    "from tensorflow import gfile\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "dsprites.DSprites\n",
    "IMAGE_PATH = 'img_align_celeba/'\n",
    "image_size = 64\n",
    "# SAMPLE_PATH = '../'\n",
    "DSPRITES_PATH = \"/home/ISO/Pruned_VAE/data/dsprites/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\"\n",
    "with gfile.Open(DSPRITES_PATH, \"rb\") as data_file:\n",
    "    # Data was saved originally using python2, so we need to set the encoding.\n",
    "    data = np.load(data_file, encoding=\"latin1\", allow_pickle=True)\n",
    "# if not os.path.exists(SAMPLE_PATH):\n",
    "#     os.makedirs(SAMPLE_PATH)\n",
    "    \n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    #transforms.Scale(image_size),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop((image_size,image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "data_loader = ImageFolder(IMAGE_PATH, transform)\n",
    "\n",
    "\n",
    "#data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "valid_loader, train_loader, test_loader = get_celeba_dataloader(data_loader, \n",
    "                                                                batch_size=128)\n",
    "test_batch = iter(test_loader)\n",
    "test_batch = next(test_batch)\n",
    "new_labels =torch.tensor(test_batch[1])\n",
    "print(torch.tensor(test_batch[0]).shape)\n",
    "#latent_dist = model.encode(torch.tensor(test_batch[0]).cuda())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "limit_a, limit_b, epsilon = -.5, 1.5, 1e-6\n",
    "eps = np.linspace(0.1,0.9,20)\n",
    "def sigmoid(x):\n",
    "    y = 1./(1.+np.exp(-x))\n",
    "    return y\n",
    "def quantile_concrete(x,temperature,qz_loga):\n",
    "        \n",
    "        \"\"\"Implements the quantile, aka inverse CDF, of the 'stretched' concrete distribution\"\"\"\n",
    "        y = sigmoid((np.log(x) - np.log(1 - x) + qz_loga) / temperature)\n",
    "        return y * (limit_b - limit_a) + limit_a\n",
    "\n",
    "z = quantile_concrete(eps,1/20,2)\n",
    "z[z>=1]=1\n",
    "z[z<=0]=0\n",
    "print(z)\n",
    "plt.plot(eps,z)\n",
    "droprate_init = 0.2\n",
    "x = torch.autograd.Variable(torch.Tensor([1, 2, 3, 4]), requires_grad=True)\n",
    "y = torch.autograd.Variable(torch.zeros(4), requires_grad=False).data.normal_(math.log(1 - droprate_init) - math.log(droprate_init), 1e-2)\n",
    "z=(x+y).detach()\n",
    "print(y)\n",
    "#z.is_leaf \n",
    "a=torch.ones((64,32))\n",
    "b=torch.ones((1,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737280, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(data[\"imgs\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "from PIL import Image\n",
    "from torch.nn.functional import normalize\n",
    "trans = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#print(np.mean(data[\"imgs\"]),np.std(data[\"imgs\"]))\n",
    "#####train\n",
    "print(normalize(torch.tensor(data[\"imgs\"]).to(dtype=torch.float32)).min())\n",
    "train_x = normalize(torch.tensor(data[\"imgs\"][:649600,:,:]).to(dtype=torch.float32)) # a list of numpy arrays\n",
    "train_y = torch.zeros((data[\"imgs\"][:649600,:,:].shape[0],1)) # another list of numpy arrays (targets)\n",
    "train_set = utils.TensorDataset(train_x,train_y) # create your datset\n",
    "train_loader = utils.DataLoader(train_set, batch_size=64) # create your dataloader\n",
    "\n",
    "#####test\n",
    "test_x = normalize(torch.tensor(data[\"imgs\"][649600:704000,:,:]).to(dtype=torch.float32)) # a list of numpy arrays\n",
    "test_y = torch.zeros((data[\"imgs\"][649600:704000,:,:].shape[0],1)) # another list of numpy arrays (targets)\n",
    "test_set = utils.TensorDataset(test_x,test_y) # create your datset\n",
    "test_loader = utils.DataLoader(test_set, batch_size=64) # create your dataloader\n",
    "\n",
    "#####valid\n",
    "valid_x = normalize( torch.tensor(data[\"imgs\"][700000:,:,:]).to(dtype=torch.float32))# a list of numpy arrays\n",
    "valid_y = torch.zeros((data[\"imgs\"][700000:,:,:].shape[0],1)) # another list of numpy arrays (targets)\n",
    "valid_set = utils.TensorDataset(valid_x,valid_y) # create your datset\n",
    "valid_loader = utils.DataLoader(valid_set, batch_size=64) # create your dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define latent distribution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (img_to_features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (features_to_hidden): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc_latent): Sequential(\n",
      "    (0): L0Pair(256 -> 2*10, droprate_init=0.2, lamba=0.1, temperature=0.05, weight_decay=0.001, local_rep=False)\n",
      "  )\n",
      "  (fc_alphas): ModuleList()\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (features_to_img): Sequential(\n",
      "    (0): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloaders import get_mnist_dataloaders, get_celeba_dataloader \n",
    "from torchvision import transforms \n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader \n",
    "import os \n",
    "import torch\n",
    "from jointvae.models_f import VAE\n",
    "from jointvae.training import Trainer\n",
    "from torch import optim\n",
    "from viz.visualize_c import Visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#valid_loader, train_loader, test_loader = get_mnist_dataloaders(batch_size=64)\n",
    "\n",
    "# Latent distribution will be joint distribution of 10 gaussian normal distributions  7-14\n",
    "# and one 10 dimensional Gumbel Softmax distribution\n",
    "n_cont = 10\n",
    "disc = []\n",
    "n_disc = len(disc)\n",
    "latent_spec = {'cont': n_cont,\n",
    "               'disc': disc}\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = VAE(latent_spec=latent_spec, img_size=(1, 64, 64)).cuda()\n",
    "# model = VAE(latent_spec=latent_spec, img_size=(1, 32, 32)).cuda()\n",
    "print(model)\n",
    "\n",
    "\n",
    "lr=0.00005\n",
    "# Build optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# Define the capacities\n",
    "# Continuous channels\n",
    "gamma=1.0\n",
    "cont_capacity = [0.0, 0.0, 25000, gamma]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "# Discrete channels\n",
    "disc_capacity = [0.0, 0.0, 25000, gamma]  # Starting at a capacity of 0.0, increase this to 5.0\n",
    "                                         # over 25000 iterations with a gamma of 30.0\n",
    "\n",
    "\n",
    "lambda_d = 2\n",
    "lambda_od = 10*lambda_d\n",
    "lambda_dis = 20*lambda_d \n",
    "path=\"./Evaluations/\".format(n_cont,gamma,lambda_d)\n",
    "# Build a trainer\n",
    "trainer = Trainer(model, optimizer,\n",
    "                  cont_capacity=cont_capacity,\n",
    "                  disc_capacity=disc_capacity,lambda_d = lambda_d,\n",
    "                  lambda_od = lambda_od, lambda_dis = lambda_dis )\n",
    "# Build a visualizer which will be passed to trainer to visualize progress during training\n",
    "viz = Visualizer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from jointvae.training import Trainer\n",
    "\n",
    "\n",
    "trainer._train_epoch(train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/649600\tLoss: 1665.873\tL0 Loss: 0.529\n",
      "3200/649600\tLoss: 1652.259\tL0 Loss: 0.529\n",
      "6400/649600\tLoss: 1618.457\tL0 Loss: 0.529\n",
      "9600/649600\tLoss: 1230.365\tL0 Loss: 0.529\n",
      "12800/649600\tLoss: 1066.357\tL0 Loss: 0.529\n",
      "16000/649600\tLoss: 1053.292\tL0 Loss: 0.529\n",
      "19200/649600\tLoss: 1045.385\tL0 Loss: 0.529\n",
      "22400/649600\tLoss: 1041.192\tL0 Loss: 0.529\n",
      "25600/649600\tLoss: 1039.395\tL0 Loss: 0.529\n",
      "28800/649600\tLoss: 1037.769\tL0 Loss: 0.529\n",
      "32000/649600\tLoss: 1036.850\tL0 Loss: 0.529\n",
      "35200/649600\tLoss: 1033.188\tL0 Loss: 0.530\n",
      "38400/649600\tLoss: 1029.240\tL0 Loss: 0.530\n",
      "41600/649600\tLoss: 1026.996\tL0 Loss: 0.530\n",
      "44800/649600\tLoss: 1021.457\tL0 Loss: 0.530\n",
      "48000/649600\tLoss: 1020.095\tL0 Loss: 0.530\n",
      "51200/649600\tLoss: 1019.855\tL0 Loss: 0.530\n",
      "54400/649600\tLoss: 1019.647\tL0 Loss: 0.530\n",
      "57600/649600\tLoss: 1019.306\tL0 Loss: 0.530\n",
      "60800/649600\tLoss: 1019.339\tL0 Loss: 0.530\n",
      "64000/649600\tLoss: 1019.502\tL0 Loss: 0.530\n",
      "67200/649600\tLoss: 1019.156\tL0 Loss: 0.530\n",
      "70400/649600\tLoss: 1018.928\tL0 Loss: 0.530\n",
      "73600/649600\tLoss: 1018.625\tL0 Loss: 0.530\n",
      "76800/649600\tLoss: 1019.772\tL0 Loss: 0.530\n",
      "80000/649600\tLoss: 1019.270\tL0 Loss: 0.530\n",
      "83200/649600\tLoss: 1015.746\tL0 Loss: 0.530\n",
      "86400/649600\tLoss: 1010.001\tL0 Loss: 0.530\n",
      "89600/649600\tLoss: 1010.427\tL0 Loss: 0.530\n",
      "92800/649600\tLoss: 1010.245\tL0 Loss: 0.530\n",
      "96000/649600\tLoss: 1010.546\tL0 Loss: 0.530\n",
      "99200/649600\tLoss: 1009.601\tL0 Loss: 0.530\n",
      "102400/649600\tLoss: 1010.085\tL0 Loss: 0.530\n",
      "105600/649600\tLoss: 1010.305\tL0 Loss: 0.530\n",
      "108800/649600\tLoss: 1009.930\tL0 Loss: 0.530\n",
      "112000/649600\tLoss: 1009.956\tL0 Loss: 0.530\n",
      "115200/649600\tLoss: 1010.037\tL0 Loss: 0.530\n",
      "118400/649600\tLoss: 1009.990\tL0 Loss: 0.530\n",
      "121600/649600\tLoss: 1010.323\tL0 Loss: 0.530\n",
      "124800/649600\tLoss: 1004.639\tL0 Loss: 0.530\n",
      "128000/649600\tLoss: 1000.775\tL0 Loss: 0.530\n",
      "131200/649600\tLoss: 1000.252\tL0 Loss: 0.530\n",
      "134400/649600\tLoss: 1000.797\tL0 Loss: 0.530\n",
      "137600/649600\tLoss: 1000.171\tL0 Loss: 0.530\n",
      "140800/649600\tLoss: 1000.159\tL0 Loss: 0.530\n",
      "144000/649600\tLoss: 1000.744\tL0 Loss: 0.530\n",
      "147200/649600\tLoss: 1000.359\tL0 Loss: 0.530\n",
      "150400/649600\tLoss: 1000.191\tL0 Loss: 0.530\n",
      "153600/649600\tLoss: 1000.448\tL0 Loss: 0.530\n",
      "156800/649600\tLoss: 1000.237\tL0 Loss: 0.530\n",
      "160000/649600\tLoss: 1000.255\tL0 Loss: 0.530\n",
      "163200/649600\tLoss: 1000.278\tL0 Loss: 0.530\n",
      "166400/649600\tLoss: 992.916\tL0 Loss: 0.530\n",
      "169600/649600\tLoss: 990.343\tL0 Loss: 0.530\n",
      "172800/649600\tLoss: 990.028\tL0 Loss: 0.530\n",
      "176000/649600\tLoss: 990.708\tL0 Loss: 0.530\n",
      "179200/649600\tLoss: 989.811\tL0 Loss: 0.530\n",
      "182400/649600\tLoss: 989.505\tL0 Loss: 0.530\n",
      "185600/649600\tLoss: 990.973\tL0 Loss: 0.530\n",
      "188800/649600\tLoss: 989.783\tL0 Loss: 0.530\n",
      "192000/649600\tLoss: 989.547\tL0 Loss: 0.530\n",
      "195200/649600\tLoss: 990.602\tL0 Loss: 0.530\n",
      "198400/649600\tLoss: 989.684\tL0 Loss: 0.530\n",
      "201600/649600\tLoss: 989.864\tL0 Loss: 0.530\n",
      "204800/649600\tLoss: 990.648\tL0 Loss: 0.530\n",
      "208000/649600\tLoss: 979.582\tL0 Loss: 0.530\n",
      "211200/649600\tLoss: 978.648\tL0 Loss: 0.530\n",
      "214400/649600\tLoss: 979.038\tL0 Loss: 0.530\n",
      "217600/649600\tLoss: 980.280\tL0 Loss: 0.531\n",
      "220800/649600\tLoss: 978.348\tL0 Loss: 0.531\n",
      "224000/649600\tLoss: 978.955\tL0 Loss: 0.531\n",
      "227200/649600\tLoss: 980.038\tL0 Loss: 0.531\n",
      "230400/649600\tLoss: 978.753\tL0 Loss: 0.531\n",
      "233600/649600\tLoss: 978.903\tL0 Loss: 0.531\n",
      "236800/649600\tLoss: 979.856\tL0 Loss: 0.531\n",
      "240000/649600\tLoss: 978.583\tL0 Loss: 0.531\n",
      "243200/649600\tLoss: 978.536\tL0 Loss: 0.531\n",
      "246400/649600\tLoss: 990.540\tL0 Loss: 0.531\n",
      "249600/649600\tLoss: 1028.822\tL0 Loss: 0.531\n",
      "252800/649600\tLoss: 1029.236\tL0 Loss: 0.531\n",
      "256000/649600\tLoss: 1030.195\tL0 Loss: 0.531\n",
      "259200/649600\tLoss: 1030.262\tL0 Loss: 0.531\n",
      "262400/649600\tLoss: 1029.343\tL0 Loss: 0.531\n",
      "265600/649600\tLoss: 1028.917\tL0 Loss: 0.531\n",
      "268800/649600\tLoss: 1028.934\tL0 Loss: 0.531\n",
      "272000/649600\tLoss: 1029.184\tL0 Loss: 0.531\n",
      "275200/649600\tLoss: 1030.026\tL0 Loss: 0.531\n",
      "278400/649600\tLoss: 1030.438\tL0 Loss: 0.531\n",
      "281600/649600\tLoss: 1029.397\tL0 Loss: 0.531\n",
      "284800/649600\tLoss: 1029.231\tL0 Loss: 0.531\n",
      "288000/649600\tLoss: 1025.685\tL0 Loss: 0.531\n",
      "291200/649600\tLoss: 1022.132\tL0 Loss: 0.531\n",
      "294400/649600\tLoss: 1023.270\tL0 Loss: 0.531\n",
      "297600/649600\tLoss: 1024.405\tL0 Loss: 0.531\n",
      "300800/649600\tLoss: 1024.570\tL0 Loss: 0.531\n",
      "304000/649600\tLoss: 1023.021\tL0 Loss: 0.531\n",
      "307200/649600\tLoss: 1021.578\tL0 Loss: 0.531\n",
      "310400/649600\tLoss: 1021.935\tL0 Loss: 0.531\n",
      "313600/649600\tLoss: 1022.722\tL0 Loss: 0.531\n",
      "316800/649600\tLoss: 1024.166\tL0 Loss: 0.531\n",
      "320000/649600\tLoss: 1024.203\tL0 Loss: 0.531\n",
      "323200/649600\tLoss: 1022.743\tL0 Loss: 0.531\n",
      "326400/649600\tLoss: 1022.136\tL0 Loss: 0.531\n",
      "329600/649600\tLoss: 1016.960\tL0 Loss: 0.531\n",
      "332800/649600\tLoss: 1014.496\tL0 Loss: 0.531\n",
      "336000/649600\tLoss: 1016.551\tL0 Loss: 0.531\n",
      "339200/649600\tLoss: 1017.967\tL0 Loss: 0.531\n",
      "342400/649600\tLoss: 1017.112\tL0 Loss: 0.531\n",
      "345600/649600\tLoss: 1015.410\tL0 Loss: 0.531\n",
      "348800/649600\tLoss: 1014.089\tL0 Loss: 0.531\n",
      "352000/649600\tLoss: 1014.454\tL0 Loss: 0.531\n",
      "355200/649600\tLoss: 1016.096\tL0 Loss: 0.531\n",
      "358400/649600\tLoss: 1017.863\tL0 Loss: 0.531\n",
      "361600/649600\tLoss: 1017.864\tL0 Loss: 0.531\n",
      "364800/649600\tLoss: 1015.662\tL0 Loss: 0.531\n",
      "368000/649600\tLoss: 1014.157\tL0 Loss: 0.531\n",
      "371200/649600\tLoss: 1007.145\tL0 Loss: 0.531\n",
      "374400/649600\tLoss: 1006.556\tL0 Loss: 0.531\n",
      "377600/649600\tLoss: 1008.237\tL0 Loss: 0.531\n",
      "380800/649600\tLoss: 1010.483\tL0 Loss: 0.531\n",
      "384000/649600\tLoss: 1007.955\tL0 Loss: 0.532\n",
      "387200/649600\tLoss: 1005.134\tL0 Loss: 0.532\n",
      "390400/649600\tLoss: 1003.787\tL0 Loss: 0.532\n",
      "393600/649600\tLoss: 1004.286\tL0 Loss: 0.532\n",
      "396800/649600\tLoss: 1006.523\tL0 Loss: 0.532\n",
      "400000/649600\tLoss: 1008.439\tL0 Loss: 0.532\n",
      "403200/649600\tLoss: 1007.152\tL0 Loss: 0.532\n",
      "406400/649600\tLoss: 1004.560\tL0 Loss: 0.532\n",
      "409600/649600\tLoss: 1002.593\tL0 Loss: 0.532\n",
      "412800/649600\tLoss: 993.513\tL0 Loss: 0.532\n",
      "416000/649600\tLoss: 995.223\tL0 Loss: 0.532\n",
      "419200/649600\tLoss: 999.126\tL0 Loss: 0.532\n",
      "422400/649600\tLoss: 1000.402\tL0 Loss: 0.532\n",
      "425600/649600\tLoss: 997.187\tL0 Loss: 0.532\n",
      "428800/649600\tLoss: 993.841\tL0 Loss: 0.532\n",
      "432000/649600\tLoss: 992.747\tL0 Loss: 0.532\n",
      "435200/649600\tLoss: 993.942\tL0 Loss: 0.532\n",
      "438400/649600\tLoss: 997.583\tL0 Loss: 0.532\n",
      "441600/649600\tLoss: 999.977\tL0 Loss: 0.532\n",
      "444800/649600\tLoss: 997.587\tL0 Loss: 0.532\n",
      "448000/649600\tLoss: 993.580\tL0 Loss: 0.532\n",
      "451200/649600\tLoss: 990.164\tL0 Loss: 0.532\n",
      "454400/649600\tLoss: 982.909\tL0 Loss: 0.532\n",
      "457600/649600\tLoss: 986.255\tL0 Loss: 0.532\n",
      "460800/649600\tLoss: 991.132\tL0 Loss: 0.532\n",
      "464000/649600\tLoss: 991.237\tL0 Loss: 0.532\n",
      "467200/649600\tLoss: 986.613\tL0 Loss: 0.532\n",
      "470400/649600\tLoss: 982.906\tL0 Loss: 0.532\n",
      "473600/649600\tLoss: 982.376\tL0 Loss: 0.532\n",
      "476800/649600\tLoss: 984.678\tL0 Loss: 0.532\n",
      "480000/649600\tLoss: 989.669\tL0 Loss: 0.532\n",
      "483200/649600\tLoss: 992.243\tL0 Loss: 0.532\n",
      "486400/649600\tLoss: 987.540\tL0 Loss: 0.532\n",
      "489600/649600\tLoss: 983.786\tL0 Loss: 0.532\n",
      "492800/649600\tLoss: 1002.888\tL0 Loss: 0.532\n",
      "496000/649600\tLoss: 1030.074\tL0 Loss: 0.532\n",
      "499200/649600\tLoss: 1028.406\tL0 Loss: 0.532\n",
      "502400/649600\tLoss: 1028.448\tL0 Loss: 0.532\n",
      "505600/649600\tLoss: 1028.605\tL0 Loss: 0.533\n",
      "508800/649600\tLoss: 1028.293\tL0 Loss: 0.533\n",
      "512000/649600\tLoss: 1027.862\tL0 Loss: 0.533\n",
      "515200/649600\tLoss: 1028.067\tL0 Loss: 0.533\n",
      "518400/649600\tLoss: 1027.552\tL0 Loss: 0.533\n",
      "521600/649600\tLoss: 1028.245\tL0 Loss: 0.533\n",
      "524800/649600\tLoss: 1028.164\tL0 Loss: 0.533\n",
      "528000/649600\tLoss: 1027.682\tL0 Loss: 0.533\n",
      "531200/649600\tLoss: 1027.223\tL0 Loss: 0.533\n",
      "534400/649600\tLoss: 1023.951\tL0 Loss: 0.533\n",
      "537600/649600\tLoss: 1022.051\tL0 Loss: 0.533\n",
      "540800/649600\tLoss: 1022.265\tL0 Loss: 0.533\n",
      "544000/649600\tLoss: 1022.265\tL0 Loss: 0.533\n",
      "547200/649600\tLoss: 1022.387\tL0 Loss: 0.533\n",
      "550400/649600\tLoss: 1021.898\tL0 Loss: 0.533\n",
      "553600/649600\tLoss: 1021.410\tL0 Loss: 0.533\n",
      "556800/649600\tLoss: 1021.798\tL0 Loss: 0.533\n",
      "560000/649600\tLoss: 1021.945\tL0 Loss: 0.533\n",
      "563200/649600\tLoss: 1022.296\tL0 Loss: 0.533\n",
      "566400/649600\tLoss: 1021.796\tL0 Loss: 0.533\n",
      "569600/649600\tLoss: 1021.184\tL0 Loss: 0.533\n",
      "572800/649600\tLoss: 1021.041\tL0 Loss: 0.533\n",
      "576000/649600\tLoss: 1016.706\tL0 Loss: 0.533\n",
      "579200/649600\tLoss: 1015.825\tL0 Loss: 0.533\n",
      "582400/649600\tLoss: 1016.144\tL0 Loss: 0.533\n",
      "585600/649600\tLoss: 1016.611\tL0 Loss: 0.533\n",
      "588800/649600\tLoss: 1015.801\tL0 Loss: 0.533\n",
      "592000/649600\tLoss: 1015.533\tL0 Loss: 0.533\n",
      "595200/649600\tLoss: 1014.909\tL0 Loss: 0.533\n",
      "598400/649600\tLoss: 1015.530\tL0 Loss: 0.533\n",
      "601600/649600\tLoss: 1016.108\tL0 Loss: 0.533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604800/649600\tLoss: 1016.387\tL0 Loss: 0.533\n",
      "608000/649600\tLoss: 1016.106\tL0 Loss: 0.533\n",
      "611200/649600\tLoss: 1015.924\tL0 Loss: 0.533\n",
      "614400/649600\tLoss: 1014.967\tL0 Loss: 0.534\n",
      "617600/649600\tLoss: 1009.091\tL0 Loss: 0.534\n",
      "620800/649600\tLoss: 1009.316\tL0 Loss: 0.534\n",
      "624000/649600\tLoss: 1009.662\tL0 Loss: 0.534\n",
      "627200/649600\tLoss: 1009.787\tL0 Loss: 0.534\n",
      "630400/649600\tLoss: 1008.886\tL0 Loss: 0.534\n",
      "633600/649600\tLoss: 1008.369\tL0 Loss: 0.534\n",
      "636800/649600\tLoss: 1007.961\tL0 Loss: 0.534\n",
      "640000/649600\tLoss: 1008.568\tL0 Loss: 0.534\n",
      "643200/649600\tLoss: 1008.538\tL0 Loss: 0.534\n",
      "646400/649600\tLoss: 1009.294\tL0 Loss: 0.534\n",
      "Valid Loss: 1048.731, Recon Error: 0.239\n",
      "1048.7308802923658\n",
      "Epoch: 1 Average loss: 1017.67 Valid loss: 1048.7308802923658\tRecon Error:0.239\n",
      "0/649600\tLoss: 1017.321\tL0 Loss: 0.534\n",
      "3200/649600\tLoss: 1018.877\tL0 Loss: 0.534\n",
      "6400/649600\tLoss: 1018.232\tL0 Loss: 0.534\n",
      "9600/649600\tLoss: 1018.101\tL0 Loss: 0.534\n",
      "12800/649600\tLoss: 1018.728\tL0 Loss: 0.534\n",
      "16000/649600\tLoss: 1018.170\tL0 Loss: 0.534\n",
      "19200/649600\tLoss: 1017.956\tL0 Loss: 0.534\n",
      "22400/649600\tLoss: 1018.162\tL0 Loss: 0.534\n",
      "25600/649600\tLoss: 1017.882\tL0 Loss: 0.534\n",
      "28800/649600\tLoss: 1017.898\tL0 Loss: 0.534\n",
      "32000/649600\tLoss: 1018.375\tL0 Loss: 0.534\n",
      "35200/649600\tLoss: 1017.613\tL0 Loss: 0.534\n",
      "38400/649600\tLoss: 1018.033\tL0 Loss: 0.534\n",
      "41600/649600\tLoss: 1016.423\tL0 Loss: 0.534\n",
      "44800/649600\tLoss: 1010.940\tL0 Loss: 0.534\n",
      "48000/649600\tLoss: 1010.011\tL0 Loss: 0.534\n",
      "51200/649600\tLoss: 1009.939\tL0 Loss: 0.534\n",
      "54400/649600\tLoss: 1010.207\tL0 Loss: 0.534\n",
      "57600/649600\tLoss: 1009.346\tL0 Loss: 0.534\n",
      "60800/649600\tLoss: 1010.072\tL0 Loss: 0.534\n",
      "64000/649600\tLoss: 1009.705\tL0 Loss: 0.534\n",
      "67200/649600\tLoss: 1009.238\tL0 Loss: 0.534\n",
      "70400/649600\tLoss: 1009.552\tL0 Loss: 0.534\n",
      "73600/649600\tLoss: 1009.774\tL0 Loss: 0.534\n",
      "76800/649600\tLoss: 1008.971\tL0 Loss: 0.535\n",
      "80000/649600\tLoss: 1009.363\tL0 Loss: 0.535\n",
      "83200/649600\tLoss: 1007.343\tL0 Loss: 0.535\n",
      "86400/649600\tLoss: 1001.010\tL0 Loss: 0.535\n",
      "89600/649600\tLoss: 1000.562\tL0 Loss: 0.535\n",
      "92800/649600\tLoss: 1000.268\tL0 Loss: 0.535\n",
      "96000/649600\tLoss: 1000.431\tL0 Loss: 0.535\n",
      "99200/649600\tLoss: 999.815\tL0 Loss: 0.535\n",
      "102400/649600\tLoss: 1000.193\tL0 Loss: 0.535\n",
      "105600/649600\tLoss: 1000.519\tL0 Loss: 0.535\n",
      "108800/649600\tLoss: 999.744\tL0 Loss: 0.535\n",
      "112000/649600\tLoss: 999.703\tL0 Loss: 0.535\n",
      "115200/649600\tLoss: 1000.293\tL0 Loss: 0.535\n",
      "118400/649600\tLoss: 999.716\tL0 Loss: 0.535\n",
      "121600/649600\tLoss: 999.921\tL0 Loss: 0.535\n",
      "124800/649600\tLoss: 996.621\tL0 Loss: 0.535\n",
      "128000/649600\tLoss: 990.863\tL0 Loss: 0.535\n",
      "131200/649600\tLoss: 990.382\tL0 Loss: 0.535\n",
      "134400/649600\tLoss: 991.015\tL0 Loss: 0.535\n",
      "137600/649600\tLoss: 990.938\tL0 Loss: 0.535\n",
      "140800/649600\tLoss: 990.263\tL0 Loss: 0.535\n",
      "144000/649600\tLoss: 990.894\tL0 Loss: 0.535\n",
      "147200/649600\tLoss: 990.079\tL0 Loss: 0.535\n",
      "150400/649600\tLoss: 989.814\tL0 Loss: 0.535\n",
      "153600/649600\tLoss: 990.719\tL0 Loss: 0.535\n",
      "156800/649600\tLoss: 990.438\tL0 Loss: 0.535\n",
      "160000/649600\tLoss: 989.936\tL0 Loss: 0.535\n",
      "163200/649600\tLoss: 989.753\tL0 Loss: 0.535\n",
      "166400/649600\tLoss: 984.159\tL0 Loss: 0.535\n",
      "169600/649600\tLoss: 979.927\tL0 Loss: 0.535\n",
      "172800/649600\tLoss: 980.102\tL0 Loss: 0.535\n",
      "176000/649600\tLoss: 980.903\tL0 Loss: 0.535\n",
      "179200/649600\tLoss: 979.670\tL0 Loss: 0.536\n",
      "182400/649600\tLoss: 979.461\tL0 Loss: 0.536\n",
      "185600/649600\tLoss: 980.979\tL0 Loss: 0.536\n",
      "188800/649600\tLoss: 979.947\tL0 Loss: 0.536\n",
      "192000/649600\tLoss: 979.187\tL0 Loss: 0.536\n",
      "195200/649600\tLoss: 980.457\tL0 Loss: 0.536\n",
      "198400/649600\tLoss: 979.783\tL0 Loss: 0.536\n",
      "201600/649600\tLoss: 979.266\tL0 Loss: 0.536\n",
      "204800/649600\tLoss: 980.073\tL0 Loss: 0.536\n",
      "208000/649600\tLoss: 970.743\tL0 Loss: 0.536\n",
      "211200/649600\tLoss: 968.452\tL0 Loss: 0.536\n",
      "214400/649600\tLoss: 969.297\tL0 Loss: 0.536\n",
      "217600/649600\tLoss: 969.844\tL0 Loss: 0.536\n",
      "220800/649600\tLoss: 968.751\tL0 Loss: 0.536\n",
      "224000/649600\tLoss: 968.781\tL0 Loss: 0.536\n",
      "227200/649600\tLoss: 970.405\tL0 Loss: 0.536\n",
      "230400/649600\tLoss: 968.297\tL0 Loss: 0.536\n",
      "233600/649600\tLoss: 968.736\tL0 Loss: 0.536\n",
      "236800/649600\tLoss: 969.951\tL0 Loss: 0.536\n",
      "240000/649600\tLoss: 968.683\tL0 Loss: 0.536\n",
      "243200/649600\tLoss: 968.475\tL0 Loss: 0.536\n",
      "246400/649600\tLoss: 982.560\tL0 Loss: 0.536\n",
      "249600/649600\tLoss: 1024.557\tL0 Loss: 0.536\n",
      "252800/649600\tLoss: 1021.315\tL0 Loss: 0.536\n",
      "256000/649600\tLoss: 1020.523\tL0 Loss: 0.536\n"
     ]
    }
   ],
   "source": [
    "# Train model for 10 epochs\n",
    "# Note this should really be a 100 epochs and trained on a GPU, but this is just to demo\n",
    "###1e-5 6859 1e-4 6727 5e-4 6722 try tanh/L1 loss/beta--->DIP\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "trainer.train(train_loader,valid_loader, epochs=50, save_training_gif=('./training.gif', viz))\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "torch.save(trainer.best_model.state_dict(), 'model_params.pkl')\n",
    "torch.save(trainer.best_model, './model')\n",
    "##15.078 - 0.0147  17.209 - 0.0168 error tanh \n",
    "##LR 1e-3 0.019-0.023 worse should pick 5e-4\n",
    "##PLOT THE CURVE!!!!!\n",
    "###3360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(latent_spec=latent_spec, img_size=(1, 64, 64)).cuda()\n",
    "model.load_state_dict(torch.load('model_params.pkl'))\n",
    "#path=\"figures/face/cont_{}/pruned_Beta_ {}lamba{}_ONLYPAIR\".format(n_cont,gamma,0.1)\n",
    "loss = trainer.get_losses()\n",
    "# print(len(loss[\"DIP_loss\"]))\n",
    "# print(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for batch, labels in test_loader:\n",
    "    break\n",
    "batch = torch.unsqueeze(batch,1).cuda().to(dtype=torch.float32)\n",
    "latent, mask, reg = model.encode(batch)\n",
    "model.reparameterize(latent).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0627 03:01:14.505311 140529698576128 deprecation_wrapper.py:119] From /data/anaconda/envs/mli/lib/python3.6/site-packages/gin/tf/utils.py:34: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0627 03:01:14.506554 140529698576128 deprecation_wrapper.py:119] From /data/anaconda/envs/mli/lib/python3.6/site-packages/gin/tf/utils.py:34: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "W0627 03:01:14.507223 140529698576128 deprecation_wrapper.py:119] From /data/anaconda/envs/mli/lib/python3.6/site-packages/gin/tf/utils.py:43: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "/data/anaconda/envs/mli/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/data/anaconda/envs/mli/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/data/anaconda/envs/mli/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/data/anaconda/envs/mli/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from disentanglement_lib.evaluation.metrics import beta_vae,  factor_vae,dci, mig, modularity_explicitness, sap_score\n",
    "from disentanglement_lib.data.ground_truth import dsprites\n",
    "dataset = dsprites.DSprites()\n",
    "##########\n",
    "def representation_fn(x, mean = True):\n",
    "    x = torch.tensor(x).cuda(device=0).to(dtype=torch.float32)\n",
    "    model = VAE(latent_spec = latent_spec, img_size=(1, 64, 64)).cuda(device=0)\n",
    "    model.load_state_dict(torch.load('model_params.pkl'))\n",
    "    latent_dict,mask,regularization = model.encode(x)\n",
    "\n",
    "    if mean:\n",
    "        return latent_dict[\"cont\"][0][0]\n",
    "    else:\n",
    "        return model.reparameterize(latent_dict).cuda(device=0)  \n",
    "    \n",
    "    \n",
    "######\n",
    "beta_scores_dict = beta_vae.compute_beta_vae_sklearn(ground_truth_data = dataset,representation_function = representation_fn)\n",
    "factor_scores_dict = factor_vae.compute_factor_vae(ground_truth_data = dataset, representation_function = representation_fn)\n",
    "dci_scores = dci.compute_dci(ground_truth_data = dataset, representation_function = representation_fn)\n",
    "mig_scores_dict = mig.compute_mig(ground_truth_data = dataset, representation_function = representation_fn)\n",
    "modular_score_dict = modularity_explicitness.compute_modularity_explicitness(ground_truth_data = dataset, representation_function = representation_fn)\n",
    "sap_scores_dict = sap_score.compute_sap(ground_truth_data = dataset, representation_function = representation_fn)\n",
    "####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beta_scores_dict , factor_scores_dict,dci_scores, mig_scores_dict, modular_score_dict,sap_scores_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.cuda.is_available()\n",
    "# device = torch.device('cuda')\n",
    "# print(device)\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.get_device_name(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Chi-square test\n",
    "import torch\n",
    "tensor_one = torch.tensor([[1,2,3],[4,5,6]])\n",
    "tensor_two = torch.tensor([[6,8,9],[10,11,12]])\n",
    "tensor_list = [tensor_one, tensor_two]\n",
    "tens_list = []\n",
    "for tensor in tensor_list:\n",
    "    \n",
    "    print(tensor)\n",
    "    length = tensor.shape[1]\n",
    "    tens_list.append(torch.mean(tensor.float(),dim=0))\n",
    "    \n",
    "tens_list = torch.stack(tens_list).reshape(1,-1)\n",
    "tens_listT = tens_list.t()\n",
    "matrix = tens_listT.matmul(tens_list)\n",
    "print(matrix)\n",
    "print(\"--------\")\n",
    "Chi2 =0\n",
    "for i in range(len(tensor_list)):\n",
    "    for j in range(len(tensor_list)):\n",
    "        if i > j:\n",
    "            submatrix = matrix[j*length:(j+1)*length,i*length:(i+1)*length]\n",
    "            c_sum = torch.sum(submatrix,dim=0).reshape(-1,1)\n",
    "            \n",
    "            r_sum = torch.sum(submatrix,dim=1).reshape(1,-1)\n",
    "            all_sum = torch.sum(submatrix)\n",
    "            Expectation = c_sum.matmul(r_sum)/all_sum\n",
    "            print(all_sum,c_sum,r_sum,Expectation)\n",
    "            Chi2 += torch.sum((submatrix-Expectation)**2/Expectation)\n",
    "            \n",
    "        \n",
    "print(Chi2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8)\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd8201fccf8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot reconstructions\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 10)) \n",
    "# Get a batch of data\n",
    "for batch, labels in test_loader:\n",
    "    break\n",
    "    \n",
    "#get best model,easrly stopping\n",
    "viz = Visualizer(model)\n",
    "\n",
    "# Reconstruct data using Joint-VAE model\n",
    "recon = viz.reconstructions(torch.unsqueeze(batch,1).cuda().to(dtype=torch.float32))\n",
    "\n",
    "# face\n",
    "recon=np.rollaxis(recon.numpy(), 0, 3)  \n",
    "print(recon[265:,:,:].min())\n",
    "recon[:,:,:]=recon[:,:,:]\n",
    "plt.imshow(recon[:,:,:].astype(float),cmap=\"gray\",vmin=0, vmax=1)\n",
    "\n",
    "#MNIST\n",
    "# plt.imshow(recon.numpy()[0, :, :].astype(float), cmap='gray')\n",
    "#plt.savefig(path+\"/recon.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_batch = iter(test_loader)\n",
    "test_batch = next(test_batch)\n",
    "latent_dist,mask,_ = model.encode(torch.unsqueeze(test_batch[0],1).cuda().to(dtype=torch.float32))\n",
    "\n",
    "print(mask,len(torch.nonzero(mask[0]==0)))\n",
    "\n",
    "# for latent in latent_dist['cont'][0]:\n",
    "#     count=torch.zeros((1,32))\n",
    "#     latent[latent<1e-7]=0\n",
    "    \n",
    "#     for i in range(128):\n",
    "    \n",
    "#     #print(latent[i].size(),torch.nonzero(latent[i]))#len(torch.nonzero(latent[0]==0))\n",
    "#         count[latent[i].reshape(1,32)!=0] += 1\n",
    "#     print(count)\n",
    "def show_idx(mask):\n",
    "    a = mask.cpu().detach().numpy().squeeze()\n",
    "    return np.array(np.where(a==1))+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TCR():\n",
    "    totalc = 0\n",
    "    for batch, labels in test_loader:\n",
    "        latent_dist, mask, reg = model.encode(torch.tensor(batch).cuda())\n",
    "        mean, var = latent_dist['cont'][0]\n",
    "        cov = covmatrix(mean)\n",
    "        cov[torch.abs(cov)<=1e-6]=0\n",
    "        cor = cov2cor(cov)\n",
    "        totalc += np.sum(cor) \n",
    "\n",
    "    return totalc/len(test_loader)\n",
    "\n",
    "def TCV():\n",
    "    totalc = 0\n",
    "    for batch, labels in test_loader:\n",
    "        latent_dist,mask, reg = model.encode(torch.tensor(batch).cuda())\n",
    "        mean, var = latent_dist['cont'][0]\n",
    "        cov = covmatrix(mean).cpu().detach().numpy()\n",
    "        cov = cov-np.diag(np.diag(cov))\n",
    "        totalc += np.sum(cov**2) \n",
    "        \n",
    "    return totalc/len(test_loader)\n",
    "\n",
    "\n",
    "def covmatrix(mean):\n",
    "    exp_mu = torch.mean(mean, dim=0)  #####mean through batch\n",
    "\n",
    "    # expectation of mu mu.tranpose\n",
    "    mu_expand1 = mean.unsqueeze(1)  #####(batch_size, 1, number of mean of latent variables)\n",
    "    mu_expand2 = mean.unsqueeze(2)  #####(batch_size, number of mean of latent variables, 1) ignore batch_size, only transpose the means\n",
    "    exp_mu_mu_t = torch.mean(mu_expand1 * mu_expand2, dim=0)\n",
    "\n",
    "    # covariance of model mean\n",
    "    cov = exp_mu_mu_t - exp_mu.unsqueeze(0) * exp_mu.unsqueeze(1) \n",
    "    return cov\n",
    "def cov2cor(c):\n",
    "    #input batch * n_cont\n",
    "    c = c.cpu().detach()\n",
    "    d=np.zeros_like(c)\n",
    "    for i in range(c.shape[0]):\n",
    "        for j in range(c.shape[1]):\n",
    "            d[i,j]=c[i,j]/(np.sqrt(c[i,i]*c[j,j]+1e-10))\n",
    "    return d\n",
    "tcor=TCR()\n",
    "tcov=TCV()\n",
    "print(tcor,tcov)\n",
    "trainer.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###latent space T-SNE visualization\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "samples = torch.zeros(1)\n",
    "labels = torch.zeros(1)\n",
    "for i in range(10):\n",
    "    test_batch = iter(test_loader)\n",
    "    test_batch = next(test_batch)\n",
    "    new_labels =torch.tensor(test_batch[1])\n",
    "    latent_dist,_ ,_= model.encode(torch.tensor(test_batch[0]).cuda())\n",
    "    new_samples = model.reparameterize(latent_dist)\n",
    "    if torch.sum(samples) == 0:\n",
    "        samples =new_samples\n",
    "        labels = new_labels\n",
    "    else:\n",
    "        samples = torch.cat((samples,new_samples),0)\n",
    "        labels = torch.cat((labels, new_labels),0)\n",
    "    #print(samples.shape)\n",
    "    \n",
    "##latent_varibales should be N,D--->N,2\n",
    "\n",
    "\n",
    "# latent_variables = samples.reshape(samples[0],-1)\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "tsne.fit_transform(samples.detach().cpu().numpy())\n",
    "\n",
    "plt.scatter(tsne.embedding_[:,0],tsne.embedding_[:,1])\n",
    "#plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 10 # Number of labels\n",
    "\n",
    "# setup the plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "# define the data\n",
    "x = tsne.embedding_[:,0]\n",
    "y = tsne.embedding_[:,1]\n",
    "tag = labels# Tag each point with a corresponding label    \n",
    "\n",
    "# define the colormap\n",
    "cmap = plt.cm.jet\n",
    "# extract all colors from the .jet map\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "# create the new map\n",
    "cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "# define the bins and normalize\n",
    "bounds = np.linspace(0,N,N+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# make the scatter\n",
    "scat = ax.scatter(x,y,c=tag,s=np.random.randint(100,110,N),cmap=cmap,     norm=norm)\n",
    "# create the colorbar\n",
    "cb = plt.colorbar(scat, spacing='proportional',ticks=bounds)\n",
    "cb.set_label('Custom cbar')\n",
    "ax.set_title('Discrete color mappings')\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "plt.savefig(path+\"/scatter.png\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "t-SNE demo\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X = np.arange(40).reshape(5,4,2)\n",
    "\n",
    "X_new = X.reshape(5,-1)\n",
    "#X = np.array([[[0,0], [0,0], [0,0]], [[0,0], [0,1], [1,1]], [[1,1], [1,0], [0,1]], [[1,1], [1,1], [1,1]]])\n",
    "print(X.shape,X)\n",
    "print(\"--------\")\n",
    "print(X_new)\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit_transform(X)\n",
    "print(tsne.embedding_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot samples\n",
    "\n",
    "samples = viz.samples()\n",
    "plt.imshow(samples.numpy()[0, :174, :], cmap='gray')\n",
    "print(np.sum(samples.numpy()[0, :174, :]))\n",
    "print(samples.numpy()[0, :, :].shape)\n",
    "####origin\n",
    "4*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot samples\n",
    "import matplotlib as mpl\n",
    "\n",
    "#MNIST\n",
    "# samples = viz.samples()\n",
    "# sample=samples.numpy()[0, :, :]/2+0.5\n",
    "# plt.imshow(sample, cmap='gray')\n",
    "# plt.imsave(path+\"/samples\",samples.numpy()[0, :, :]/2+0.5, cmap='gray')\n",
    "\n",
    "# face\n",
    "fig = plt.figure(figsize=(50, 50)) \n",
    "samples = viz.samples()\n",
    "samples = np.rollaxis(samples.numpy(), 0, 3)  \n",
    "print(samples[:,:,0].max())\n",
    "samples=(samples+1)/2\n",
    "plt.imshow(samples.astype(float),norm = norm)\n",
    "plt.imsave(path+\"/samples\",samples)\n",
    "###DIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot all traversals\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "traversals = viz.all_latent_traversals(size=10)\n",
    "\n",
    "#MNIST\n",
    "# plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "# plt.imsave(path+\"/all_traversals\",traversals.numpy()[0, :, :], cmap='gray')\n",
    "\n",
    "#face\n",
    "traversals = np.rollaxis(traversals.numpy(), 0, 3)  \n",
    "traversals=(traversals+1)/2\n",
    "plt.imshow(traversals)\n",
    "plt.imsave(path+\"/all_traversals\",traversals)\n",
    "###dip[0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
    "#         0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a grid of some traversals\n",
    "traversals = viz.latent_traversal_grid(cont_idx=5, cont_axis=1, disc_idx=0, disc_axis=0, size=(10, 10))\n",
    "#MNIST\n",
    "# plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "# plt.imsave(path+\"/contVSdisc\",traversals.numpy()[0, :, :], cmap='gray')\n",
    "\n",
    "traversals.numpy()[0, :, :].max()\n",
    "show_idx(mask)\n",
    "#face\n",
    "traversals = np.rollaxis(traversals.numpy(), 0, 3)\n",
    "traversals=(traversals+1)/2\n",
    "plt.imshow(traversals)\n",
    "plt.imsave(path+\"/contVSdisc\",traversals)\n",
    "##origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_t = viz.all_latent_traversals()\n",
    "print(all_t.shape)\n",
    "plt.imshow(all_t.numpy()[0, :, :], cmap='gray')\n",
    "plt.imsave(\"figures/beta/all_\",traversals.numpy()[0, :, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "# Plot a grid of some traversals\n",
    "\n",
    "fig = plt.figure(figsize=(70, 70))  # width, height in inches\n",
    "print(\"continuous\")\n",
    "for i in range(n_cont):\n",
    "    traversals = viz.latent_traversal_line(cont_idx=i, disc_idx=None,size=12)\n",
    "    \n",
    "    #MNIST\n",
    "#     sub = fig.add_subplot(n_cont, 1, i + 1)\n",
    "#     plt.savefig(path+\"/cont{}.png\".format(i))\n",
    "#     plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "    \n",
    "    #FACE\n",
    "    traversals = np.rollaxis(traversals.numpy(), 0, 3)\n",
    "    sub = fig.add_subplot(n_cont, 1, i + 1)\n",
    "    traversals=(traversals+1)/2\n",
    "    plt.imshow(traversals)   \n",
    "plt.savefig(path+\"/cont.png\")\n",
    "\n",
    "show_idx(mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"discrete\")\n",
    "for i in range(n_disc):\n",
    "    traversals = viz.latent_traversal_line(cont_idx=None, disc_idx=i,size=10)\n",
    "    ##MNIST\n",
    "#     sub = fig.add_subplot(n_disc, 1, i + 1)\n",
    "#     plt.savefig(path+\"/disc{}.png\".format(i))\n",
    "#     plt.imshow(traversals.numpy()[0, :, :], cmap='gray')\n",
    "\n",
    "    #FACE\n",
    "    traversals = np.rollaxis(traversals.numpy(), 0, 3)\n",
    "    sub = fig.add_subplot(n_disc, 1, i + 1)\n",
    "traversals=(traversals+1)/2\n",
    "plt.savefig(path+\"/disc{}.png\".format(i))\n",
    "plt.imshow(traversals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from latent_traversals import LatentTraverser\n",
    "from scipy import stats\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import numpy as np\n",
    "import torch\n",
    "from latent_traversals import LatentTraverser\n",
    "from scipy import stats\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "    \n",
    "# face    \n",
    "def single_traversal(model,n_cont,cont_idx,cont_v,disc,disc_idx,prior):\n",
    "\n",
    "        # Generate latent traversal\n",
    "#         latent_samples = latent_traverser.traverse_line(cont_idx=cont_idx,\n",
    "#                                                              disc_idx=disc_idx,\n",
    "#                                                              size=size)\n",
    "        dim = n_cont + sum(disc)\n",
    "        if prior:\n",
    "            latent_samples = torch.tensor(np.random.normal(size=(1, dim)))\n",
    "        else:\n",
    "            latent_samples= torch.zeros((1,dim))\n",
    "            \n",
    "        latent_samples[:,disc_idx+n_cont-1] = 1.0\n",
    "        latent_samples[:,cont_idx]=cont_v\n",
    "        \n",
    "\n",
    "        # Map samples through decoder\n",
    "        generated = decode_latents(model, latent_samples.float()).squeeze()\n",
    "        generated  = np.rollaxis(generated.detach().numpy(), 0, 3)\n",
    "        generated = (generated +1)/2\n",
    "        print(generated.min(),generated.max())\n",
    "        plt.imshow(generated)\n",
    "\n",
    "        \n",
    "def decode_latents(model, latent_samples):\n",
    "\n",
    "        latent_samples = Variable(latent_samples)\n",
    "        if model.use_cuda:\n",
    "            latent_samples = latent_samples.cuda()\n",
    "            result = model.decode(latent_samples).cpu()\n",
    "        return result\n",
    "\n",
    "#MNIST\n",
    "# def single_traversal(model,n_cont,cont_idx,cont_v,disc,disc_idx,prior):\n",
    "\n",
    "#        # Generate latent traversal\n",
    "#         latent_samples = latent_traverser.traverse_line(cont_idx=cont_idx,\n",
    "#                                                              disc_idx=disc_idx,\n",
    "#                                                              size=size)\n",
    "#         dim = n_cont + sum(disc)\n",
    "#         if prior:\n",
    "#             latent_samples = torch.tensor(np.random.normal(size=(1, dim)))\n",
    "#         else:\n",
    "#             latent_samples= torch.zeros((1,dim))\n",
    "            \n",
    "#         latent_samples[:,disc_idx+n_cont-1] = 1.0\n",
    "#         latent_samples[:,cont_idx]=cont_v\n",
    "        \n",
    "\n",
    "#         # Map samples through decoder\n",
    "#         generated = decode_latents(model, latent_samples.float()).squeeze()\n",
    "#         plt.imshow(generated.detach().numpy(),cmap=\"gray\")\n",
    "\n",
    "        \n",
    "# def decode_latents(model, latent_samples):\n",
    "\n",
    "#         latent_samples = Variable(latent_samples)\n",
    "#         if model.use_cuda:\n",
    "#             latent_samples = latent_samples.cuda()\n",
    "#         return model.decode(latent_samples).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import display\n",
    "def interactive_view(model,n_cont,disc):\n",
    "    \n",
    "    \n",
    "    interact(single_traversal,model=fixed(model),\n",
    "             n_cont=fixed(n_cont), cont_idx=(0,n_cont,1), cont_v=(-2.5,2.5,0.5),\n",
    "             disc=fixed(disc),disc_idx=(0,9,1),\n",
    "             prior=True);\n",
    "             \n",
    "interactive_view(model,n_cont,disc)\n",
    "show_idx(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
